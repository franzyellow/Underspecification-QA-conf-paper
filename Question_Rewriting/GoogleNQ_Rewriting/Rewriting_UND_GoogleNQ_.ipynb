{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1de948a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "from typing import List, Literal, List, Dict, Any\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy import LabeledFewShot\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from functools import partial\n",
    "from datasets import Dataset\n",
    "from copy import deepcopy\n",
    "import evaluate\n",
    "import nltk\n",
    "from scipy.stats import ttest_ind\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import AnswerAccuracy\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38e1bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116 samples with F1 score of 0\n",
      "Successfully extracted 20 samples with F1=0 to produced_files/GoogleNQ_UND_gpt_f1_zero_samples.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Extract 20 random samples with F1 score of 0 from JSONL file\n",
    "def extract_f1_zero_samples(input_file, output_file, num_samples=20):\n",
    "    \"\"\"\n",
    "    Randomly extract specified number of samples with F1 score of 0 from JSONL file\n",
    "    \n",
    "    Args:\n",
    "        input_file: Input JSONL file path\n",
    "        output_file: Output JSONL file path\n",
    "        num_samples: Number of samples to extract\n",
    "    \"\"\"\n",
    "    f1_zero_samples = []\n",
    "    \n",
    "    # Read all data and filter samples with F1 score of 0\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            if data.get('f1') == 0:\n",
    "                f1_zero_samples.append(data)\n",
    "    \n",
    "    print(f\"Found {len(f1_zero_samples)} samples with F1 score of 0\")\n",
    "    \n",
    "    # If F1=0 samples are fewer than requested, use all available\n",
    "    if len(f1_zero_samples) < num_samples:\n",
    "        print(f\"Only {len(f1_zero_samples)} samples with F1=0 available, less than requested {num_samples}\")\n",
    "        selected_samples = f1_zero_samples\n",
    "    else:\n",
    "        # Randomly sample the specified number of samples\n",
    "        selected_samples = random.sample(f1_zero_samples, num_samples)\n",
    "    \n",
    "    # Write to new JSONL file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sample in selected_samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"Successfully extracted {len(selected_samples)} samples with F1=0 to {output_file}\")\n",
    "    return selected_samples\n",
    "\n",
    "# Set file paths\n",
    "input_file = \"produced_files/GoogleNQ_UND_gpt_with_most_metrics.jsonl\"\n",
    "output_file = \"produced_files/GoogleNQ_UND_gpt_f1_zero_samples.jsonl\"\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "random.seed(42)\n",
    "\n",
    "# Execute extraction\n",
    "selected_samples = extract_f1_zero_samples(input_file, output_file, num_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93f0dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_low_f1_samples(input_file, output_file, threshold):\n",
    "    \"\"\"\n",
    "    Randomly extract specified number of samples with low f1 score from JSONL file\n",
    "    \n",
    "    Args:\n",
    "        input_file: Input JSONL file path\n",
    "        output_file: Output JSONL file path\n",
    "    \"\"\"\n",
    "    target_samples = []\n",
    "    \n",
    "    # Read all data and filter samples with F1 score of 0\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            if data.get('f1') <= threshold:\n",
    "                target_samples.append(data)\n",
    "    \n",
    "    print(f\"Found {len(target_samples)} samples satisfying the defined condition\")\n",
    "    \n",
    "    # Write to new JSONL file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sample in target_samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"Successfully extracted {len(target_samples)} samples with F1 <= {threshold} to {output_file}\")\n",
    "    return target_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cca58fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 samples satisfying the defined condition\n",
      "Successfully extracted 156 samples with F1 <= 0.2 to produced_files/GoogleNQ_UND_gpt_low_f1_samples.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Set file paths\n",
    "input_file = \"produced_files/GoogleNQ_UND_gpt_with_most_metrics.jsonl\"\n",
    "output_file = \"produced_files/GoogleNQ_UND_gpt_low_f1_samples.jsonl\"\n",
    "\n",
    "# Execute extraction\n",
    "\n",
    "selected_samples = retrieve_all_low_f1_samples(input_file, output_file, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0d57f",
   "metadata": {},
   "source": [
    "## Question Modification using Gemini 2.5 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81ad88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75fcc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_question_with_gemini(question, short_answer, reasoning, model=\"gemini-2.5-flash\", temperature=0, max_retries=5, sleep_time=2.0):\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a professional question optimization expert. Please modify the underspecified question to a fully specified version based on the provided clues.\\n\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"1. Keep the core intent of the question unchanged\\n\"\n",
    "        \"2. Add necessary contextual information\\n\"\n",
    "        \"3. Eliminate underspecified elements and make the question clear\\n\"\n",
    "        \"4. Ensure the modified question can be directly answered with the provided short answer without dispute\\n\\n\"\n",
    "        \"Please only return the modified question, do not include any other explanations.\"\n",
    "    )\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "The original question: {question}\n",
    "Short answer: {short_answer}\n",
    "Reasoning: {reasoning}\n",
    "\n",
    "Please analyze the underspecified elements in the original question, then modify the question to a fully specified version based on the short answer and reasoning.\n",
    "\"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            modified_question = content.strip()\n",
    "            return modified_question\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Attempt {retries} failed: {str(e)}\")\n",
    "            if retries < max_retries:\n",
    "                print(f\"Waiting {sleep_time * retries} seconds before retry...\")\n",
    "                time.sleep(sleep_time * retries)\n",
    "            else:\n",
    "                print(f\"All retries failed, returning original question\")\n",
    "                return question  # If error occurs, return original question\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa74755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "test_question = \"when did the smoking ban in public places start\"\n",
    "test_short_answer = ['1995']\n",
    "test_reasoning = \"The request is underspecified because the phrase 'public places' is vague and depends on the specific jurisdiction or country being referenced. Smoking bans vary significantly across different regions, and without specifying the location, the question lacks a necessary component to determine the correct answer.\"\n",
    "\n",
    "print(\"Testing Gemini API connection...\")\n",
    "try:\n",
    "    test_result = modify_question_with_gemini(test_question, test_short_answer, test_reasoning)\n",
    "    print(f\"Original question: {test_question}\")\n",
    "    print(f\"Modified question: {test_result}\")\n",
    "    print(\"API connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"API connection failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19ffdabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modification_in_batch(input_file, output_file, batch_size=5):\n",
    "    \"\"\"\n",
    "    按批次处理所有样本，提高处理效率\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入JSONL文件路径\n",
    "        output_file: 输出JSONL文件路径\n",
    "        batch_size: 每批处理的样本数量\n",
    "    \n",
    "    Returns:\n",
    "        list: 所有处理过的样本\n",
    "    \"\"\"\n",
    "    \n",
    "    all_processed_samples = []\n",
    "    \n",
    "    # Loading all the data from the input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    total_samples = len(lines)\n",
    "    print(f\"Total samples to process: {total_samples}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    # Process all samples in batches\n",
    "    for batch_start in tqdm(range(0, total_samples, batch_size), desc=\"Processing batches\"):\n",
    "        batch_end = min(batch_start + batch_size, total_samples)\n",
    "        batch_lines = lines[batch_start:batch_end]\n",
    "        \n",
    "        batch_processed_samples = []\n",
    "        \n",
    "        # Process each sample in the current batch\n",
    "        for i, line in enumerate(batch_lines):\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                \n",
    "                # Extract necessary fields\n",
    "                question = data['question']\n",
    "                short_answer = data['short_answers']\n",
    "                reasoning = data['reasoning']\n",
    "                \n",
    "                # Modify questions\n",
    "                modified_question = modify_question_with_gemini(question, short_answer, reasoning)\n",
    "                \n",
    "                # Create new data structure\n",
    "                new_sample = {\n",
    "                    'original_question': question,\n",
    "                    'modified_question': modified_question,\n",
    "                    'short_answer': short_answer,\n",
    "                    'model_original_answer': data.get('model_short_answer', 'undefined'),\n",
    "                    'classifier_reasoning': reasoning,\n",
    "                    'category': data.get('category', 'undefined'),\n",
    "                    'original_f1': data.get('f1', 'undefined'),\n",
    "                    'original_em': data.get('em', 'undefined')\n",
    "                }\n",
    "                \n",
    "                batch_processed_samples.append(new_sample)\n",
    "                \n",
    "                # Add delay to avoid API rate limits\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {batch_start + i + 1}: {e}\")\n",
    "                # Create error sample to maintain consistency\n",
    "                error_sample = {\n",
    "                    'original_question': data.get('question', 'error'),\n",
    "                    'modified_question': 'error',\n",
    "                    'short_answer': data.get('short_answers', ['error']),\n",
    "                    'model_original_answer': data.get('model_short_answer', 'error'),\n",
    "                    'classifier_reasoning': data.get('reasoning', 'error'),\n",
    "                    'category': data.get('category', 'error'),\n",
    "                    'original_f1': data.get('f1', 'error'),\n",
    "                    'original_em': data.get('em', 'error')\n",
    "                }\n",
    "                batch_processed_samples.append(error_sample)\n",
    "        \n",
    "        # Add batch results to all processed samples\n",
    "        all_processed_samples.extend(batch_processed_samples)\n",
    "        \n",
    "        # Write intermediate results to file (append mode)\n",
    "        with open(output_file, 'a', encoding='utf-8') as f:\n",
    "            for sample in batch_processed_samples:\n",
    "                f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "    \n",
    "    print(f\"\\nAll batch processing completed! Total processed: {len(all_processed_samples)} samples\")\n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    return all_processed_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "773817de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples to process: 156\n",
      "Batch size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|          | 0/52 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  25%|██▌       | 13/52 [09:51<26:13, 40.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: 'NoneType' object has no attribute 'strip'\n",
      "Waiting 2.0 seconds before retry...\n",
      "Attempt 2 failed: 'NoneType' object has no attribute 'strip'\n",
      "Waiting 4.0 seconds before retry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 43/52 [36:57<05:17, 35.26s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: 'NoneType' object has no attribute 'strip'\n",
      "Waiting 2.0 seconds before retry...\n",
      "Attempt 2 failed: 'NoneType' object has no attribute 'strip'\n",
      "Waiting 4.0 seconds before retry...\n",
      "Attempt 3 failed: 'NoneType' object has no attribute 'strip'\n",
      "Waiting 6.0 seconds before retry...\n",
      "Attempt 4 failed: 'NoneType' object has no attribute 'strip'\n",
      "Waiting 8.0 seconds before retry...\n",
      "Attempt 5 failed: 'NoneType' object has no attribute 'strip'\n",
      "All retries failed, returning original question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 52/52 [1:05:31<00:00, 75.61s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All batch processing completed! Total processed: 156 samples\n",
      "Results saved to: produced_files/GoogleNQ_UND_gpt_low_f1_samples_modified.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 清空输出文件（如果存在）\n",
    "modified_output_file = \"produced_files/GoogleNQ_UND_gpt_low_f1_samples_modified.jsonl\"\n",
    "if os.path.exists(modified_output_file):\n",
    "    os.remove(modified_output_file)\n",
    "    print(f\"Cleared existing output file: {modified_output_file}\")\n",
    "\n",
    "# 处理所有样本（按批次）\n",
    "question_modification = modification_in_batch(output_file, modified_output_file, batch_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c09646a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question</th>\n",
       "      <th>modified_question</th>\n",
       "      <th>short_answer</th>\n",
       "      <th>model_original_answer</th>\n",
       "      <th>classifier_reasoning</th>\n",
       "      <th>category</th>\n",
       "      <th>original_f1</th>\n",
       "      <th>original_em</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>where does the modern view of history originat...</td>\n",
       "      <td>When did modern historiography, emphasizing cr...</td>\n",
       "      <td>[approximately in the early 16th century]</td>\n",
       "      <td>[The modern view of history originates from th...</td>\n",
       "      <td>The request is underspecified because the phra...</td>\n",
       "      <td>Undetermined standard or preference</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when was the first book made into a movie</td>\n",
       "      <td>When was the first feature film adaptation of ...</td>\n",
       "      <td>[1924]</td>\n",
       "      <td>[1900 - 'Sherlock Holmes Baffled' based on Art...</td>\n",
       "      <td>The request is underspecified because the term...</td>\n",
       "      <td>Undetermined standard or preference</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when did the first wireless beats come out</td>\n",
       "      <td>When did the Beats Wireless headphones first c...</td>\n",
       "      <td>[October 2012]</td>\n",
       "      <td>[2014]</td>\n",
       "      <td>The request is underspecified because the term...</td>\n",
       "      <td>Undetermined lexicons or references</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the collection of the districts to the...</td>\n",
       "      <td>What are the major regions and countries locat...</td>\n",
       "      <td>[Golan Heights, Jordan]</td>\n",
       "      <td>[Transjordan]</td>\n",
       "      <td>The request is underspecified because the term...</td>\n",
       "      <td>Undetermined lexicons or references</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factories that assemble parts made in other co...</td>\n",
       "      <td>What are the designated geographical areas whe...</td>\n",
       "      <td>[special economic zones]</td>\n",
       "      <td>[Assembly plants, Maquiladoras]</td>\n",
       "      <td>The request is underspecified because the term...</td>\n",
       "      <td>Undetermined lexicons or references</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>the origins of the stations of the cross</td>\n",
       "      <td>What is the name of the path in Jerusalem that...</td>\n",
       "      <td>[Via Dolorosa in Jerusalem which is believed t...</td>\n",
       "      <td>[- The Stations of the Cross originated as a d...</td>\n",
       "      <td>The request is underspecified because the term...</td>\n",
       "      <td>Undetermined standard or preference</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>what's the medal count for canada in the olympics</td>\n",
       "      <td>What was the total medal count for Canada at t...</td>\n",
       "      <td>[302]</td>\n",
       "      <td>[Canada has won 199 gold, 173 silver, and 230 ...</td>\n",
       "      <td>The request is underspecified because it lacks...</td>\n",
       "      <td>Missing necessary components</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>when was the last time the womens hockey team ...</td>\n",
       "      <td>When was the most recent time the United State...</td>\n",
       "      <td>[2018]</td>\n",
       "      <td>[The Canadian women's hockey team won gold at ...</td>\n",
       "      <td>The request is underspecified because the phra...</td>\n",
       "      <td>Undetermined perspective or granularity</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>when does the good doctor episode 8 air</td>\n",
       "      <td>When does The Good Doctor Season 1 Episode 8 air?</td>\n",
       "      <td>[November 20, 2017]</td>\n",
       "      <td>[The air date for Episode 8 of The Good Doctor...</td>\n",
       "      <td>The request is underspecified because the phra...</td>\n",
       "      <td>Missing necessary components</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>where do royal families get their money from</td>\n",
       "      <td>What is the specific term for the traditional ...</td>\n",
       "      <td>[the hereditary revenues of the Crown]</td>\n",
       "      <td>[- Inherited wealth and assets  \\n- Government...</td>\n",
       "      <td>The request is underspecified because the term...</td>\n",
       "      <td>Undetermined lexicons or references</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_question  \\\n",
       "0    where does the modern view of history originat...   \n",
       "1            when was the first book made into a movie   \n",
       "2           when did the first wireless beats come out   \n",
       "3    what is the collection of the districts to the...   \n",
       "4    factories that assemble parts made in other co...   \n",
       "..                                                 ...   \n",
       "151           the origins of the stations of the cross   \n",
       "152  what's the medal count for canada in the olympics   \n",
       "153  when was the last time the womens hockey team ...   \n",
       "154            when does the good doctor episode 8 air   \n",
       "155       where do royal families get their money from   \n",
       "\n",
       "                                     modified_question  \\\n",
       "0    When did modern historiography, emphasizing cr...   \n",
       "1    When was the first feature film adaptation of ...   \n",
       "2    When did the Beats Wireless headphones first c...   \n",
       "3    What are the major regions and countries locat...   \n",
       "4    What are the designated geographical areas whe...   \n",
       "..                                                 ...   \n",
       "151  What is the name of the path in Jerusalem that...   \n",
       "152  What was the total medal count for Canada at t...   \n",
       "153  When was the most recent time the United State...   \n",
       "154  When does The Good Doctor Season 1 Episode 8 air?   \n",
       "155  What is the specific term for the traditional ...   \n",
       "\n",
       "                                          short_answer  \\\n",
       "0            [approximately in the early 16th century]   \n",
       "1                                               [1924]   \n",
       "2                                       [October 2012]   \n",
       "3                              [Golan Heights, Jordan]   \n",
       "4                             [special economic zones]   \n",
       "..                                                 ...   \n",
       "151  [Via Dolorosa in Jerusalem which is believed t...   \n",
       "152                                              [302]   \n",
       "153                                             [2018]   \n",
       "154                                [November 20, 2017]   \n",
       "155             [the hereditary revenues of the Crown]   \n",
       "\n",
       "                                 model_original_answer  \\\n",
       "0    [The modern view of history originates from th...   \n",
       "1    [1900 - 'Sherlock Holmes Baffled' based on Art...   \n",
       "2                                               [2014]   \n",
       "3                                        [Transjordan]   \n",
       "4                      [Assembly plants, Maquiladoras]   \n",
       "..                                                 ...   \n",
       "151  [- The Stations of the Cross originated as a d...   \n",
       "152  [Canada has won 199 gold, 173 silver, and 230 ...   \n",
       "153  [The Canadian women's hockey team won gold at ...   \n",
       "154  [The air date for Episode 8 of The Good Doctor...   \n",
       "155  [- Inherited wealth and assets  \\n- Government...   \n",
       "\n",
       "                                  classifier_reasoning  \\\n",
       "0    The request is underspecified because the phra...   \n",
       "1    The request is underspecified because the term...   \n",
       "2    The request is underspecified because the term...   \n",
       "3    The request is underspecified because the term...   \n",
       "4    The request is underspecified because the term...   \n",
       "..                                                 ...   \n",
       "151  The request is underspecified because the term...   \n",
       "152  The request is underspecified because it lacks...   \n",
       "153  The request is underspecified because the phra...   \n",
       "154  The request is underspecified because the phra...   \n",
       "155  The request is underspecified because the term...   \n",
       "\n",
       "                                    category  original_f1  original_em  \n",
       "0        Undetermined standard or preference     0.111111            0  \n",
       "1        Undetermined standard or preference     0.000000            0  \n",
       "2        Undetermined lexicons or references     0.000000            0  \n",
       "3        Undetermined lexicons or references     0.000000            0  \n",
       "4        Undetermined lexicons or references     0.000000            0  \n",
       "..                                       ...          ...          ...  \n",
       "151      Undetermined standard or preference     0.169014            0  \n",
       "152             Missing necessary components     0.000000            0  \n",
       "153  Undetermined perspective or granularity     0.000000            0  \n",
       "154             Missing necessary components     0.000000            0  \n",
       "155      Undetermined lexicons or references     0.000000            0  \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_view = pd.DataFrame(question_modification)\n",
    "#df_view.to_csv(\"produced_files/modification_pilot.csv\")\n",
    "df_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5969b69b",
   "metadata": {},
   "source": [
    "## Implementing QA on modified questions using GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c9548",
   "metadata": {},
   "source": [
    "#### Loading GPT-4o and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff234c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://api.openai.com/v1\"\n",
    ") # Delete when sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5a2739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_short_answer(question, client, model=\"gpt-4o-2024-11-20\", temperature=0, max_retries=5, sleep_time=2.0):\n",
    "    system_prompt = (\n",
    "        \"Answer the question with a concise response. \"\n",
    "        \"Return answers as a list of strings. If there's only one answer, return a single-item list. \"\n",
    "        \"Each answer should be brief and direct.\"\n",
    "    )\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": question}\n",
    "                ],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            if content.startswith(\"[\"):\n",
    "                return eval(content)\n",
    "            else:\n",
    "                return [content.strip()]\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            time.sleep(sleep_time * retries)\n",
    "            \n",
    "    return [\"[Error]: Max retries exceeded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab9a9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_shortQA_api(batch, client, **kwargs):\n",
    "    short_answers = []\n",
    "    for q in batch[\"modified_question\"]:\n",
    "        try:\n",
    "            answer = ask_short_answer(q, client=client, **kwargs)\n",
    "            short_answers.append(answer)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            short_answers.append([\"error\"])\n",
    "    return {\"model_new_answer\": short_answers}\n",
    "\n",
    "def batch_QA_with_progress(dataset, batch_fn, output_key, batch_size=10, fill_value=\"error\", **batch_fn_kwargs):\n",
    "    all_outputs = []\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=f\"Running {output_key}\"):\n",
    "        batch = dataset.select(range(i, min(i + batch_size, len(dataset))))\n",
    "        try:\n",
    "            output = batch_fn(batch, **batch_fn_kwargs)\n",
    "            if output_key not in output:\n",
    "                raise ValueError(f\"Missing key '{output_key}' in batch result\")\n",
    "            all_outputs.extend(output[output_key])\n",
    "        except Exception as e:\n",
    "            print(f\"Batch error at {i}: {e}\")\n",
    "            all_outputs.extend([fill_value] * len(batch))\n",
    "\n",
    "    if len(all_outputs) != len(dataset):\n",
    "        print(f\"[Warning] Output length mismatch, auto-filling\")\n",
    "        all_outputs.extend([fill_value] * (len(dataset) - len(all_outputs)))\n",
    "\n",
    "    return {output_key: all_outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83de6d2",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d272b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529ab889904d4ddcabe2bda4a0c5c49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modified_set = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_GoogleNQ_UND_gpt_low_AA_samples_modified.jsonl\",\n",
    "    split=\"train\"  # 必须指定 split，否则默认返回 DatasetDict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02de41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running model_new_answer: 100%|██████████| 25/25 [03:20<00:00,  8.04s/it]\n"
     ]
    }
   ],
   "source": [
    "modified_results = batch_QA_with_progress(\n",
    "    modified_set,\n",
    "    batch_fn=run_batch_shortQA_api,\n",
    "    output_key=\"model_new_answer\",\n",
    "    fill_value=[\"error\"],\n",
    "    client=client,\n",
    "    model=\"gpt-4o-2024-11-20\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccb4bf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c6a0b98bf84f989f1f1bb48c4fdc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question</th>\n",
       "      <th>modified_question</th>\n",
       "      <th>short_answer</th>\n",
       "      <th>model_original_answer</th>\n",
       "      <th>classifier_reasoning</th>\n",
       "      <th>original_f1</th>\n",
       "      <th>original_em</th>\n",
       "      <th>original_AA</th>\n",
       "      <th>model_new_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>where does the modern view of history originat...</td>\n",
       "      <td>When did the initial development of a critical...</td>\n",
       "      <td>['approximately in the early 16th century']</td>\n",
       "      <td>['The modern view of history originates from t...</td>\n",
       "      <td>The query asks about the 'modern view of histo...</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[19th century]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this inventor co-created the film fred ott’s s...</td>\n",
       "      <td>Which American inventor, known for developing ...</td>\n",
       "      <td>['Edison']</td>\n",
       "      <td>['William K.L. Dickson']</td>\n",
       "      <td>The query refers to an 'inventor' who co-creat...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[Thomas Edison]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the collection of the districts to the...</td>\n",
       "      <td>What are the primary geopolitical entities or ...</td>\n",
       "      <td>['Golan Heights' 'Jordan']</td>\n",
       "      <td>['Transjordan']</td>\n",
       "      <td>The query refers to 'the Jordan River,' which ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[The Hashemite Kingdom of Jordan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>factories that assemble parts made in other co...</td>\n",
       "      <td>What are the specific geographic areas establi...</td>\n",
       "      <td>['special economic zones']</td>\n",
       "      <td>['Assembly plants']</td>\n",
       "      <td>The query lacks specificity regarding critical...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[Export Processing Zones (EPZs)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who sang it my party and i'll cry if i want to...</td>\n",
       "      <td>Who sang the 1980s version of the song \"It's M...</td>\n",
       "      <td>['Dave Stewart and Barbara Gaskin']</td>\n",
       "      <td>['Lesley Gore']</td>\n",
       "      <td>The query appears to reference two distinct so...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Dave Stewart and Barbara Gaskin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>what's the medal count for canada in the olympics</td>\n",
       "      <td>What was Canada's total medal count across all...</td>\n",
       "      <td>['302']</td>\n",
       "      <td>['Canada has won 199 gold, 173 silver, and 230...</td>\n",
       "      <td>The query asks for Canada's medal count in the...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[302 medals]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>when was the last time the womens hockey team ...</td>\n",
       "      <td>When was the last time the United States women...</td>\n",
       "      <td>['2018']</td>\n",
       "      <td>[\"The Canadian women's hockey team won gold at...</td>\n",
       "      <td>The query lacks specification of which nationa...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[2018]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>when does the good doctor episode 8 air</td>\n",
       "      <td>When does The Good Doctor Season 1 episode 8 air?</td>\n",
       "      <td>['November 20, 2017']</td>\n",
       "      <td>['The air date for The Good Doctor Season 7, E...</td>\n",
       "      <td>The query asks for the air date of 'The Good D...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[November 20, 2017]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>where do royal families get their money from</td>\n",
       "      <td>What is the primary historical source of incom...</td>\n",
       "      <td>['the hereditary revenues of the Crown']</td>\n",
       "      <td>['- Inherited wealth and assets  \\n- Governmen...</td>\n",
       "      <td>The query is underspecified because 'royal fam...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[The Crown Estate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>what is the meaning of auv in cars</td>\n",
       "      <td>In the automotive context, what does the acron...</td>\n",
       "      <td>['action utility vehicles']</td>\n",
       "      <td>['Autonomous Underwater Vehicle' 'Automated Ut...</td>\n",
       "      <td>The query asks for the meaning of 'auv' in the...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Action Utility Vehicle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_question  \\\n",
       "0    where does the modern view of history originat...   \n",
       "1    this inventor co-created the film fred ott’s s...   \n",
       "2    what is the collection of the districts to the...   \n",
       "3    factories that assemble parts made in other co...   \n",
       "4    who sang it my party and i'll cry if i want to...   \n",
       "..                                                 ...   \n",
       "241  what's the medal count for canada in the olympics   \n",
       "242  when was the last time the womens hockey team ...   \n",
       "243            when does the good doctor episode 8 air   \n",
       "244       where do royal families get their money from   \n",
       "245                 what is the meaning of auv in cars   \n",
       "\n",
       "                                     modified_question  \\\n",
       "0    When did the initial development of a critical...   \n",
       "1    Which American inventor, known for developing ...   \n",
       "2    What are the primary geopolitical entities or ...   \n",
       "3    What are the specific geographic areas establi...   \n",
       "4    Who sang the 1980s version of the song \"It's M...   \n",
       "..                                                 ...   \n",
       "241  What was Canada's total medal count across all...   \n",
       "242  When was the last time the United States women...   \n",
       "243  When does The Good Doctor Season 1 episode 8 air?   \n",
       "244  What is the primary historical source of incom...   \n",
       "245  In the automotive context, what does the acron...   \n",
       "\n",
       "                                    short_answer  \\\n",
       "0    ['approximately in the early 16th century']   \n",
       "1                                     ['Edison']   \n",
       "2                     ['Golan Heights' 'Jordan']   \n",
       "3                     ['special economic zones']   \n",
       "4            ['Dave Stewart and Barbara Gaskin']   \n",
       "..                                           ...   \n",
       "241                                      ['302']   \n",
       "242                                     ['2018']   \n",
       "243                        ['November 20, 2017']   \n",
       "244     ['the hereditary revenues of the Crown']   \n",
       "245                  ['action utility vehicles']   \n",
       "\n",
       "                                 model_original_answer  \\\n",
       "0    ['The modern view of history originates from t...   \n",
       "1                             ['William K.L. Dickson']   \n",
       "2                                      ['Transjordan']   \n",
       "3                                  ['Assembly plants']   \n",
       "4                                      ['Lesley Gore']   \n",
       "..                                                 ...   \n",
       "241  ['Canada has won 199 gold, 173 silver, and 230...   \n",
       "242  [\"The Canadian women's hockey team won gold at...   \n",
       "243  ['The air date for The Good Doctor Season 7, E...   \n",
       "244  ['- Inherited wealth and assets  \\n- Governmen...   \n",
       "245  ['Autonomous Underwater Vehicle' 'Automated Ut...   \n",
       "\n",
       "                                  classifier_reasoning  original_f1  \\\n",
       "0    The query asks about the 'modern view of histo...     0.086957   \n",
       "1    The query refers to an 'inventor' who co-creat...     0.000000   \n",
       "2    The query refers to 'the Jordan River,' which ...     0.000000   \n",
       "3    The query lacks specificity regarding critical...     0.000000   \n",
       "4    The query appears to reference two distinct so...     0.000000   \n",
       "..                                                 ...          ...   \n",
       "241  The query asks for Canada's medal count in the...     0.000000   \n",
       "242  The query lacks specification of which nationa...     0.000000   \n",
       "243  The query asks for the air date of 'The Good D...     0.000000   \n",
       "244  The query is underspecified because 'royal fam...     0.000000   \n",
       "245  The query asks for the meaning of 'auv' in the...     0.333333   \n",
       "\n",
       "     original_em  original_AA                   model_new_answer  \n",
       "0              0         0.00                     [19th century]  \n",
       "1              0         0.25                    [Thomas Edison]  \n",
       "2              0         0.50  [The Hashemite Kingdom of Jordan]  \n",
       "3              0         0.50   [Export Processing Zones (EPZs)]  \n",
       "4              0         0.00  [Dave Stewart and Barbara Gaskin]  \n",
       "..           ...          ...                                ...  \n",
       "241            0         0.00                       [302 medals]  \n",
       "242            0         0.00                             [2018]  \n",
       "243            0         0.00                [November 20, 2017]  \n",
       "244            0         0.50                 [The Crown Estate]  \n",
       "245            0         0.00           [Action Utility Vehicle]  \n",
       "\n",
       "[246 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_modified = deepcopy(modified_set)\n",
    "for key in modified_results:\n",
    "    qa_modified = qa_modified.add_column(key, modified_results[key])\n",
    "\n",
    "qa_modified.to_json(\"BASELINE_GoogleNQ_UND_gpt_low_AA_samples_modified.jsonl\", orient=\"records\", lines=True)\n",
    "df_qa_modified = pd.read_json(\"BASELINE_GoogleNQ_UND_gpt_low_AA_samples_modified.jsonl\", lines=True)\n",
    "#df_qa_modified.to_csv('produced_files/modification_pilot_qa.csv')\n",
    "df_qa_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4430c4",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f7695b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_squad_per_sample_multi_ref_pred(dataset, pred_col=\"model_new_answer\", ref_col=\"short_answer\"):\n",
    "    \"\"\"\n",
    "    对每个样本逐一计算 EM 和 F1，支持多个参考答案和多个预测答案（list[str]）。\n",
    "    返回带 \"em\", \"f1\" 列的新 Dataset，以及 f1/em 列表用于统计分析。\n",
    "    Also considering multiple answers in both gold and pred and take the maximum score\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize_answer(s):\n",
    "        def remove_articles(text):\n",
    "            return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "        def white_space_fix(text):\n",
    "            return ' '.join(text.split())\n",
    "        def remove_punc(text):\n",
    "            return ''.join(ch for ch in text if ch not in string.punctuation)\n",
    "        def lower(text):\n",
    "            return text.lower()\n",
    "        return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "    def compute_exact(a_pred, a_gold):\n",
    "    # 如果是 list，转成 set 并 normalize 每个元素\n",
    "        if isinstance(a_pred, list) and isinstance(a_gold, list):\n",
    "          pred_set = set(normalize_answer(a) for a in a_pred)\n",
    "          gold_set = set(normalize_answer(a) for a in a_gold)\n",
    "          return int(pred_set == gold_set)\n",
    "        else:\n",
    "          return int(normalize_answer(a_pred) == normalize_answer(a_gold))\n",
    "\n",
    "    def compute_f1(a_pred, a_gold):\n",
    "        pred_tokens = normalize_answer(a_pred).split()\n",
    "        gold_tokens = normalize_answer(a_gold).split()\n",
    "        common = Counter(pred_tokens) & Counter(gold_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            return 0.0\n",
    "        precision = num_same / len(pred_tokens)\n",
    "        recall = num_same / len(gold_tokens)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    new_data = []\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "\n",
    "    for item in dataset:\n",
    "        preds = item.get(pred_col, [])\n",
    "        golds = item.get(ref_col, [])\n",
    "        # 转为 list\n",
    "        if not isinstance(preds, list):\n",
    "            preds = [preds] if preds else []\n",
    "        if not isinstance(golds, list):\n",
    "            golds = [golds] if golds else []\n",
    "\n",
    "        # 多对多最大匹配\n",
    "        if not preds or not golds:\n",
    "            em = 0.0\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            em = max(compute_exact(p, g) for p in preds for g in golds)\n",
    "            f1 = max(compute_f1(p, g) for p in preds for g in golds)\n",
    "\n",
    "        new_item = deepcopy(item)\n",
    "        new_item[\"new_em\"] = em\n",
    "        new_item[\"new_f1\"] = f1\n",
    "        new_data.append(new_item)\n",
    "        em_scores.append(em)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return Dataset.from_list(new_data), f1_scores, em_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd85a88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbf3dc5a5204d0682efa298675e45d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad_scored_modified, modified_f1_list, modified_em_list = evaluate_squad_per_sample_multi_ref_pred(qa_modified)\n",
    "squad_scored_modified.to_json(\"BASELINE_Gemini_modified_GPT_qa_squad_scores.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "df = pd.read_json(\"BASELINE_Gemini_modified_GPT_qa_squad_scores.jsonl\", lines=True)\n",
    "df.to_csv('BASELINE_Gemini_modified_GPT_qa_squad_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a12b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New answers after modification Exact Match (avg): 19.11\n",
      "New answers after modification F1 Score (avg): 44.54\n",
      "Original answers Exact Match (avg): 0.00\n",
      "Original answers F1 Score (avg): 12.67\n",
      "F1: t=12.188, p=0.0000\n",
      "EM: t=7.607, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "modified_mean_em = np.mean(modified_em_list)  # em_scores: EM list per sample\n",
    "modified_mean_f1 = np.mean(modified_f1_list)  # f1_scores F1 list per sample\n",
    "print(f\"New answers after modification Exact Match (avg): {modified_mean_em * 100:.2f}\")\n",
    "print(f\"New answers after modification F1 Score (avg): {modified_mean_f1 * 100:.2f}\")\n",
    "\n",
    "original_em_list = qa_modified['original_em']\n",
    "original_f1_list = qa_modified['original_f1']\n",
    "\n",
    "original_mean_em = np.mean(original_em_list)  # em_scores: EM list per sample\n",
    "original_mean_f1 = np.mean(original_f1_list)  # f1_scores F1 list per sample\n",
    "print(f\"Original answers Exact Match (avg): {original_mean_em * 100:.2f}\")\n",
    "print(f\"Original answers F1 Score (avg): {original_mean_f1 * 100:.2f}\")\n",
    "\n",
    "f1_tstat, f1_pval = ttest_ind(modified_f1_list, original_f1_list, equal_var=False)\n",
    "print(f\"F1: t={f1_tstat:.3f}, p={f1_pval:.4f}\")\n",
    "\n",
    "em_tstat, em_pval = ttest_ind(modified_em_list, original_em_list, equal_var=False)\n",
    "print(f\"EM: t={em_tstat:.3f}, p={em_pval:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90da8aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 查找失败的行（简单方法）===\n",
      "发现 1 个失败的行:\n",
      "\n",
      "第 130 行:\n",
      "  问题: when will the next episode of flash be aired...\n",
      "  短答案: ['May 15, 2018']\n",
      "  推理: The request is underspecified because the phrase “next episode” can refer to multiple possible refer...\n"
     ]
    }
   ],
   "source": [
    "def find_failed_rows_simple(input_file, output_file):\n",
    "    \"\"\"\n",
    "    简单方法：通过比较原问题和修改后问题是否相同来找出失败的行\n",
    "    \"\"\"\n",
    "    print(\"=== 查找失败的行（简单方法）===\")\n",
    "    \n",
    "    # 读取输入和输出文件\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        input_data = [json.loads(line.strip()) for line in f]\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        output_data = [json.loads(line.strip()) for line in f]\n",
    "    \n",
    "    failed_rows = []\n",
    "    \n",
    "    for i, (input_row, output_row) in enumerate(zip(input_data, output_data)):\n",
    "        original_question = input_row.get('question', '')\n",
    "        modified_question = output_row.get('modified_question', '')\n",
    "        \n",
    "        # 如果原问题和修改后问题相同，说明失败了\n",
    "        if original_question == modified_question:\n",
    "            failed_rows.append({\n",
    "                'row_number': i + 1,\n",
    "                'original_question': original_question,\n",
    "                'short_answer': input_row.get('short_answers', ''),\n",
    "                'reasoning': input_row.get('reasoning', '')\n",
    "            })\n",
    "    \n",
    "    print(f\"发现 {len(failed_rows)} 个失败的行:\")\n",
    "    for row in failed_rows:\n",
    "        print(f\"\\n第 {row['row_number']} 行:\")\n",
    "        print(f\"  问题: {row['original_question'][:100]}...\")\n",
    "        print(f\"  短答案: {row['short_answer']}\")\n",
    "        print(f\"  推理: {row['reasoning'][:100]}...\")\n",
    "    \n",
    "    return failed_rows\n",
    "\n",
    "# 使用简单方法查找失败的行\n",
    "failed_rows = find_failed_rows_simple(\n",
    "    \"produced_files/GoogleNQ_UND_gpt_low_f1_samples.jsonl\",\n",
    "    \"produced_files/GoogleNQ_UND_gpt_low_f1_samples_modified.jsonl\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d798dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(ChatDeepSeek(model=\"deepseek-chat\", verbose=True, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e3985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def answer_accuracy_modified(input_dataset, evaluator=evaluator_llm):\n",
    "    # 在函数开始时创建一次 scorer\n",
    "    scorer = AnswerAccuracy(llm=evaluator)\n",
    "    \n",
    "\n",
    "    score_list = []\n",
    "        \n",
    "    for i, row in enumerate(tqdm(input_dataset, desc=\"Calculating short answer accuracy\")):\n",
    "        try:\n",
    "            # 短答案评分 - 处理列表情况\n",
    "            if 'short_answer' in row and 'model_new_answer' in row:\n",
    "                model_answers = row['model_new_answer'] if isinstance(row['model_new_answer'], list) else [row['model_new_answer']]\n",
    "                reference_answers = row['short_answer'] if isinstance(row['short_answer'], list) else [row['short_answer']]\n",
    "                    \n",
    "                # 计算所有组合的分数，取最高分\n",
    "                max_score = 0.0\n",
    "                for model_ans in model_answers:\n",
    "                    for ref_ans in reference_answers:\n",
    "                        sample = SingleTurnSample(\n",
    "                                user_input=row['modified_question'],\n",
    "                                response=model_ans,\n",
    "                                reference=ref_ans\n",
    "                            )\n",
    "                        score = await scorer.single_turn_ascore(sample)\n",
    "                        max_score = max(max_score, score)\n",
    "                        if max_score == 1.0:\n",
    "                            break  # 跳出内层循环\n",
    "                    if max_score == 1.0:\n",
    "                        break  # 跳出外层循环\n",
    "                \n",
    "                score_list.append(max_score)\n",
    "            else:\n",
    "                score_list.append(0.0)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"处理第 {i+1} 个样本时出错: {e}\")\n",
    "            score_list.append(0.0)\n",
    "\n",
    "    ragas_scored_dataset = input_dataset.add_column(\"new_AA\", score_list)\n",
    "\n",
    "    return ragas_scored_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2facab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating short answer accuracy: 100%|██████████| 246/246 [40:17<00:00,  9.83s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de539f4ac1da4786a1485cf688dc8b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "221862"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_scored_modified = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_Gemini_modified_GPT_qa_squad_scores.jsonl\",\n",
    "    split=\"train\")\n",
    "result_with_AA = await answer_accuracy_modified(squad_scored_modified)\n",
    "result_with_AA.to_csv(\"BASELINE_Gemini_modified_GPT_qa_all_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9478484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original AA (avg): 21.75\n",
      "modified AA (avg): 55.79\n",
      "AA: t=10.280, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "original_AA = list(result_with_AA[\"original_AA\"])\n",
    "modified_AA = list(result_with_AA[\"new_AA\"])\n",
    "\n",
    "original_mean_AA = np.mean(original_AA)\n",
    "print(f\"original AA (avg): {original_mean_AA * 100:.2f}\")\n",
    "\n",
    "\n",
    "modified_mean_AA = np.mean(modified_AA)\n",
    "print(f\"modified AA (avg): {modified_mean_AA * 100:.2f}\")\n",
    "\n",
    "AA_tstat, AA_pval = ttest_ind(modified_AA, original_AA, equal_var=False)\n",
    "print(f\"AA: t={AA_tstat:.3f}, p={AA_pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ae2fd",
   "metadata": {},
   "source": [
    "### Including RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "217b69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../baseline_classifier_for_paper/GoogleNQ_UND_gpt4o_Ragas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399bd987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef5b0d30eda4c6e80b3b9311c962d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.to_json(\"BASELINE_GoogleNQ_UND_gpt4o_Ragas.jsonl\", orient=\"records\", lines=True)\n",
    "dataset = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_GoogleNQ_UND_gpt4o_Ragas.jsonl\",\n",
    "    split=\"train\"  # 必须指定 split，否则默认返回 DatasetDict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29658ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'short_answers', 'long_answer', 'qwen3_thinking', 'qwen3_model_response', 'qwen3_model_pred', 'model_short_answer', 'model_long_answer', 'em', 'f1', 'bleu', 'meteor', 'rouge', 'bertscore', 'ragas_AA_short'],\n",
       "    num_rows: 458\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afdd0a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The query asks about the 'modern view of history' but fails to specify critical parameters such as temporal boundaries (e.g., 18th-century Enlightenment vs. 20th-century postcolonial theory), geographic scope (e.g., Western Europe vs. global histories), disciplinary frameworks (e.g., Marxist historiography vs. traditional narrative), or key theoretical developments (e.g., source criticism vs. oral history). Additionally, 'modern view' is inherently subjective and contested among historians, further complicating the definition of an origin point.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(dataset[0]['qwen3_model_response'])['reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccbdfb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_low_AA_samples(input_file, output_file, threshold):\n",
    "    \"\"\"\n",
    "    Randomly extract specified number of samples with low f1 score from JSONL file\n",
    "    \n",
    "    Args:\n",
    "        input_file: Input JSONL file path\n",
    "        output_file: Output JSONL file path\n",
    "    \"\"\"\n",
    "    target_samples = []\n",
    "    \n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            if data.get('ragas_AA_short') < threshold:\n",
    "                target_samples.append(data)\n",
    "    \n",
    "    print(f\"Found {len(target_samples)} samples satisfying the defined condition\")\n",
    "    \n",
    "    # Write to new JSONL file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sample in target_samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"Successfully extracted {len(target_samples)} samples with Ragas AA <= {threshold} to {output_file}\")\n",
    "    return target_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62685bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 samples satisfying the defined condition\n",
      "Successfully extracted 246 samples with Ragas AA <= 1 to BASELINE_GoogleNQ_UND_gpt4o_Ragas_low_AA.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_file = \"BASELINE_GoogleNQ_UND_gpt4o_Ragas.jsonl\"\n",
    "output_file = \"BASELINE_GoogleNQ_UND_gpt4o_Ragas_low_AA.jsonl\"\n",
    "target_samples = retrieve_all_low_AA_samples(input_file, output_file, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "add88592",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "def modify_question_with_gemini(question, short_answer, reasoning, model=\"gemini-2.5-flash\", temperature=0, max_retries=5, sleep_time=2.0):\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a professional question optimization expert. Please modify the underspecified question to a fully specified version based on the provided clues.\\n\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"1. Keep the core intent of the question unchanged\\n\"\n",
    "        \"2. Add necessary contextual information\\n\"\n",
    "        \"3. Eliminate underspecified elements and make the question clear\\n\"\n",
    "        \"4. Ensure the modified question can be directly answered with the provided short answer without dispute\\n\\n\"\n",
    "        \"Please only return the modified question, do not include any other explanations.\"\n",
    "    )\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "The original question: {question}\n",
    "Short answer: {short_answer}\n",
    "Reasoning: {reasoning}\n",
    "\n",
    "Please analyze the underspecified elements in the original question, then modify the question to a fully specified version based on the short answer and reasoning.\n",
    "\"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            modified_question = content.strip()\n",
    "            return modified_question\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Attempt {retries} failed: {str(e)}\")\n",
    "            if retries < max_retries:\n",
    "                print(f\"Waiting {sleep_time * retries} seconds before retry...\")\n",
    "                time.sleep(sleep_time * retries)\n",
    "            else:\n",
    "                print(f\"All retries failed, returning original question\")\n",
    "                return question  # If error occurs, return original question\n",
    "\n",
    "def modification_in_batch_alt(input_file, output_file, batch_size=5):\n",
    "    \"\"\"\n",
    "    按批次处理所有样本，提高处理效率\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入JSONL文件路径\n",
    "        output_file: 输出JSONL文件路径\n",
    "        batch_size: 每批处理的样本数量\n",
    "    \n",
    "    Returns:\n",
    "        list: 所有处理过的样本\n",
    "    \"\"\"\n",
    "    \n",
    "    all_processed_samples = []\n",
    "    \n",
    "    # Loading all the data from the input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    total_samples = len(lines)\n",
    "    print(f\"Total samples to process: {total_samples}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    # Process all samples in batches\n",
    "    for batch_start in tqdm(range(0, total_samples, batch_size), desc=\"Processing batches\"):\n",
    "        batch_end = min(batch_start + batch_size, total_samples)\n",
    "        batch_lines = lines[batch_start:batch_end]\n",
    "        \n",
    "        batch_processed_samples = []\n",
    "        \n",
    "        # Process each sample in the current batch\n",
    "        for i, line in enumerate(batch_lines):\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                \n",
    "                # Extract necessary fields\n",
    "                question = data['question']\n",
    "                short_answer = data['short_answers']\n",
    "                classifier_response = data['qwen3_model_response']\n",
    "                classifier_reasoning = json.loads(classifier_response)['reasoning']\n",
    "                \n",
    "                # Modify questions\n",
    "                modified_question = modify_question_with_gemini(question, short_answer, classifier_reasoning)\n",
    "                \n",
    "                # Create new data structure\n",
    "                new_sample = {\n",
    "                    'original_question': question,\n",
    "                    'modified_question': modified_question,\n",
    "                    'short_answer': short_answer,\n",
    "                    'model_original_answer': data.get('model_short_answer', 'undefined'),\n",
    "                    'classifier_reasoning': classifier_reasoning,\n",
    "                    'original_f1': data.get('f1', 'undefined'),\n",
    "                    'original_em': data.get('em', 'undefined'),\n",
    "                    'original_AA': data.get('ragas_AA_short', 'undefined')\n",
    "                }\n",
    "                \n",
    "                batch_processed_samples.append(new_sample)\n",
    "                \n",
    "                # Add delay to avoid API rate limits\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {batch_start + i + 1}: {e}\")\n",
    "                # Create error sample to maintain consistency\n",
    "                error_sample = {\n",
    "                    'original_question': question,\n",
    "                    'modified_question': modified_question,\n",
    "                    'short_answer': short_answer,\n",
    "                    'model_original_answer': data.get('model_short_answer', 'error'),\n",
    "                    'classifier_reasoning': classifier_reasoning,\n",
    "                    'original_f1': data.get('f1', 'error'),\n",
    "                    'original_em': data.get('em', 'error'),\n",
    "                    'original_AA': data.get('ragas_AA_short', 'error')\n",
    "                }\n",
    "                batch_processed_samples.append(error_sample)\n",
    "        \n",
    "        # Add batch results to all processed samples\n",
    "        all_processed_samples.extend(batch_processed_samples)\n",
    "        \n",
    "        # Write intermediate results to file (append mode)\n",
    "        with open(output_file, 'a', encoding='utf-8') as f:\n",
    "            for sample in batch_processed_samples:\n",
    "                f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "    \n",
    "    print(f\"\\nAll batch processing completed! Total processed: {len(all_processed_samples)} samples\")\n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    return all_processed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3221d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples to process: 246\n",
      "Batch size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 82/82 [1:07:34<00:00, 49.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All batch processing completed! Total processed: 246 samples\n",
      "Results saved to: BASELINE_GoogleNQ_UND_gpt_low_AA_samples_modified.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 清空输出文件（如果存在）\n",
    "modified_output_file = \"BASELINE_GoogleNQ_UND_gpt_low_AA_samples_modified.jsonl\"\n",
    "if os.path.exists(modified_output_file):\n",
    "    os.remove(modified_output_file)\n",
    "    print(f\"Cleared existing output file: {modified_output_file}\")\n",
    "\n",
    "# 处理所有样本（按批次）\n",
    "question_modification = modification_in_batch_alt(output_file, modified_output_file, batch_size=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

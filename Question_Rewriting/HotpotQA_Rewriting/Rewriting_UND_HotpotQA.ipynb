{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8393de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "from typing import List, Literal, List, Dict, Any\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy import LabeledFewShot\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from functools import partial\n",
    "from datasets import Dataset\n",
    "from copy import deepcopy\n",
    "import evaluate\n",
    "import nltk\n",
    "from scipy.stats import ttest_ind\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import AnswerAccuracy\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf755b0",
   "metadata": {},
   "source": [
    "## RAGAS-AA filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b44cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_low_AA_samples(input_file, output_file, threshold):\n",
    "    \"\"\"\n",
    "    Randomly extract specified number of samples with low f1 score from JSONL file\n",
    "    \n",
    "    Args:\n",
    "        input_file: Input JSONL file path\n",
    "        output_file: Output JSONL file path\n",
    "    \"\"\"\n",
    "    target_samples = []\n",
    "    \n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            if data.get('ragas_AA_short') < threshold:\n",
    "                target_samples.append(data)\n",
    "    \n",
    "    print(f\"Found {len(target_samples)} samples satisfying the defined condition\")\n",
    "    \n",
    "    # Write to new JSONL file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sample in target_samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"Successfully extracted {len(target_samples)} samples with Ragas AA <= {threshold} to {output_file}\")\n",
    "    return target_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae57fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f4d74429d94d759fda18b1222d6716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../baseline_classifier_for_paper/HotpotQA_UND_gpt4o_Ragas.csv\")\n",
    "df.to_json(\"BASELINE_HotpotQA_UND_gpt4o_Ragas.jsonl\", orient=\"records\", lines=True)\n",
    "dataset = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_HotpotQA_UND_gpt4o_Ragas.jsonl\",\n",
    "    split=\"train\"  # 必须指定 split，否则默认返回 DatasetDict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4718204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 samples satisfying the defined condition\n",
      "Successfully extracted 324 samples with Ragas AA <= 1 to BASELINE_HotpotQA_UND_gpt4o_Ragas_low_AA.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_file = \"BASELINE_HotpotQA_UND_gpt4o_Ragas.jsonl\"\n",
    "output_file = \"BASELINE_HotpotQA_UND_gpt4o_Ragas_low_AA.jsonl\"\n",
    "target_samples = retrieve_all_low_AA_samples(input_file, output_file, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac26f06",
   "metadata": {},
   "source": [
    "## Rewriting with Gemini-2.5-Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db960c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "def modify_question_with_gemini(question, short_answer, reasoning, model=\"gemini-2.5-flash\", temperature=0, max_retries=5, sleep_time=2.0):\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a professional question optimization expert. Please modify the underspecified question to a fully specified version based on the provided clues.\\n\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"1. Keep the core intent of the question unchanged\\n\"\n",
    "        \"2. Add necessary contextual information\\n\"\n",
    "        \"3. Eliminate underspecified elements and make the question clear\\n\"\n",
    "        \"4. Ensure the modified question can be directly answered with the provided short answer without dispute\\n\\n\"\n",
    "        \"Please only return the modified question, do not include any other explanations.\"\n",
    "    )\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "The original question: {question}\n",
    "Short answer: {short_answer}\n",
    "Reasoning: {reasoning}\n",
    "\n",
    "Please analyze the underspecified elements in the original question, then modify the question to a fully specified version based on the short answer and reasoning.\n",
    "\"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            modified_question = content.strip()\n",
    "            return modified_question\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Attempt {retries} failed: {str(e)}\")\n",
    "            if retries < max_retries:\n",
    "                print(f\"Waiting {sleep_time * retries} seconds before retry...\")\n",
    "                time.sleep(sleep_time * retries)\n",
    "            else:\n",
    "                print(f\"All retries failed, returning original question\")\n",
    "                return question  # If error occurs, return original question\n",
    "\n",
    "def modification_in_batch_alt(input_file, output_file, ref_col, batch_size=5):\n",
    "    \"\"\"\n",
    "    按批次处理所有样本，提高处理效率\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入JSONL文件路径\n",
    "        output_file: 输出JSONL文件路径\n",
    "        batch_size: 每批处理的样本数量\n",
    "    \n",
    "    Returns:\n",
    "        list: 所有处理过的样本\n",
    "    \"\"\"\n",
    "    \n",
    "    all_processed_samples = []\n",
    "    \n",
    "    # Loading all the data from the input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    total_samples = len(lines)\n",
    "    print(f\"Total samples to process: {total_samples}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    # Process all samples in batches\n",
    "    for batch_start in tqdm(range(0, total_samples, batch_size), desc=\"Processing batches\"):\n",
    "        batch_end = min(batch_start + batch_size, total_samples)\n",
    "        batch_lines = lines[batch_start:batch_end]\n",
    "        \n",
    "        batch_processed_samples = []\n",
    "        \n",
    "        # Process each sample in the current batch\n",
    "        for i, line in enumerate(batch_lines):\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                \n",
    "                # Extract necessary fields\n",
    "                question = data['question']\n",
    "                short_answer = data[ref_col]\n",
    "                classifier_response = data['qwen3_model_response']\n",
    "                classifier_reasoning = json.loads(classifier_response)['reasoning']\n",
    "                \n",
    "                # Modify questions\n",
    "                modified_question = modify_question_with_gemini(question, short_answer, classifier_reasoning)\n",
    "                \n",
    "                # Create new data structure\n",
    "                new_sample = {\n",
    "                    'original_question': question,\n",
    "                    'modified_question': modified_question,\n",
    "                    'short_answer': short_answer,\n",
    "                    'model_original_answer': data.get('model_short_answer', 'undefined'),\n",
    "                    'classifier_reasoning': classifier_reasoning,\n",
    "                    'original_f1': data.get('f1', 'undefined'),\n",
    "                    'original_em': data.get('em', 'undefined'),\n",
    "                    'original_AA': data.get('ragas_AA_short', 'undefined')\n",
    "                }\n",
    "                \n",
    "                batch_processed_samples.append(new_sample)\n",
    "                \n",
    "                # Add delay to avoid API rate limits\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {batch_start + i + 1}: {e}\")\n",
    "                # Create error sample to maintain consistency\n",
    "                error_sample = {\n",
    "                    'original_question': question,\n",
    "                    'modified_question': modified_question,\n",
    "                    'short_answer': short_answer,\n",
    "                    'model_original_answer': data.get('model_short_answer', 'error'),\n",
    "                    'classifier_reasoning': classifier_reasoning,\n",
    "                    'original_f1': data.get('f1', 'error'),\n",
    "                    'original_em': data.get('em', 'error'),\n",
    "                    'original_AA': data.get('ragas_AA_short', 'error')\n",
    "                }\n",
    "                batch_processed_samples.append(error_sample)\n",
    "        \n",
    "        # Add batch results to all processed samples\n",
    "        all_processed_samples.extend(batch_processed_samples)\n",
    "        \n",
    "        # Write intermediate results to file (append mode)\n",
    "        with open(output_file, 'a', encoding='utf-8') as f:\n",
    "            for sample in batch_processed_samples:\n",
    "                f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "    \n",
    "    print(f\"\\nAll batch processing completed! Total processed: {len(all_processed_samples)} samples\")\n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    return all_processed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25633f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples to process: 324\n",
      "Batch size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  52%|█████▏    | 56/108 [1:27:47<41:06, 47.43s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing sample 170: Invalid \\escape: line 3 column 121 (char 229)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 108/108 [2:32:40<00:00, 84.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All batch processing completed! Total processed: 324 samples\n",
      "Results saved to: BASELINE_HotpotQA_UND_gpt_low_AA_samples_modified.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 清空输出文件（如果存在）\n",
    "modified_output_file = \"BASELINE_HotpotQA_UND_gpt_low_AA_samples_modified.jsonl\"\n",
    "if os.path.exists(modified_output_file):\n",
    "    os.remove(modified_output_file)\n",
    "    print(f\"Cleared existing output file: {modified_output_file}\")\n",
    "\n",
    "# 处理所有样本（按批次）\n",
    "question_modification = modification_in_batch_alt(output_file, modified_output_file, ref_col='answer', batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add4ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 查找失败的行（简单方法）===\n",
      "发现 0 个失败的行:\n"
     ]
    }
   ],
   "source": [
    "def find_failed_rows_simple(input_file, output_file):\n",
    "    \"\"\"\n",
    "    简单方法：通过比较原问题和修改后问题是否相同来找出失败的行\n",
    "    \"\"\"\n",
    "    print(\"=== 查找失败的行（简单方法）===\")\n",
    "    \n",
    "    # 读取输入和输出文件\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        input_data = [json.loads(line.strip()) for line in f]\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        output_data = [json.loads(line.strip()) for line in f]\n",
    "    \n",
    "    failed_rows = []\n",
    "    \n",
    "    for i, (input_row, output_row) in enumerate(zip(input_data, output_data)):\n",
    "        original_question = input_row.get('question', '')\n",
    "        modified_question = output_row.get('modified_question', '')\n",
    "        \n",
    "        # 如果原问题和修改后问题相同，说明失败了\n",
    "        if original_question == modified_question:\n",
    "            failed_rows.append({\n",
    "                'row_number': i + 1,\n",
    "                'original_question': original_question,\n",
    "                'short_answer': input_row.get('short_answers', ''),\n",
    "                'reasoning': input_row.get('reasoning', '')\n",
    "            })\n",
    "    \n",
    "    print(f\"发现 {len(failed_rows)} 个失败的行:\")\n",
    "    for row in failed_rows:\n",
    "        print(f\"\\n第 {row['row_number']} 行:\")\n",
    "        print(f\"  问题: {row['original_question'][:100]}...\")\n",
    "        print(f\"  短答案: {row['short_answer']}\")\n",
    "        print(f\"  推理: {row['reasoning'][:100]}...\")\n",
    "    \n",
    "    return failed_rows\n",
    "\n",
    "# 使用简单方法查找失败的行\n",
    "failed_rows = find_failed_rows_simple(\n",
    "    \"BASELINE_HotpotQA_UND_gpt4o_Ragas_low_AA.jsonl\",\n",
    "    \"BASELINE_HotpotQA_UND_gpt_low_AA_samples_modified.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb725e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question</th>\n",
       "      <th>modified_question</th>\n",
       "      <th>short_answer</th>\n",
       "      <th>model_original_answer</th>\n",
       "      <th>classifier_reasoning</th>\n",
       "      <th>original_f1</th>\n",
       "      <th>original_em</th>\n",
       "      <th>original_AA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what year was the narrator of \"Blackadder's...</td>\n",
       "      <td>In what year was Hugh Laurie, who played Princ...</td>\n",
       "      <td>['1959']</td>\n",
       "      <td>['1949']</td>\n",
       "      <td>The query seeks the birth year of the narrator...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the first two words of the fifth studi...</td>\n",
       "      <td>What are the first two words of the seventh st...</td>\n",
       "      <td>['The Hungry']</td>\n",
       "      <td>['The Patriotic']</td>\n",
       "      <td>The query references 'Joseph Edgar Foreman,' w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Earl Holding owned an oil company that ...</td>\n",
       "      <td>Robert Earl Holding owned Sinclair Oil Corpora...</td>\n",
       "      <td>['Harry F. Sinclair']</td>\n",
       "      <td>['David P. Smith']</td>\n",
       "      <td>The query requires determining the original fo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what county was Duffy Jackson born?</td>\n",
       "      <td>In what county was the jazz drummer Duffy Jack...</td>\n",
       "      <td>['Nassau County']</td>\n",
       "      <td>['Suffolk County']</td>\n",
       "      <td>The query seeks information about the birth co...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When was the defending titlist of 2009–10 Biat...</td>\n",
       "      <td>When was the biathlete who was the reigning ov...</td>\n",
       "      <td>['27 January 1974']</td>\n",
       "      <td>['March 18, 1983']</td>\n",
       "      <td>The query seeks the birth date of the 'defendi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>The saint in \"A Time for Miracles\" was born on...</td>\n",
       "      <td>What is the birth date of the saint who is the...</td>\n",
       "      <td>['August 28, 1774']</td>\n",
       "      <td>['November 26, 1774']</td>\n",
       "      <td>The query references 'A Time for Miracles,' a ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>What is the name of the presidential memorial ...</td>\n",
       "      <td>What is the name of the presidential memorial ...</td>\n",
       "      <td>['Jefferson Memorial']</td>\n",
       "      <td>['Thomas Jefferson Memorial']</td>\n",
       "      <td>The query seeks a presidential memorial in Was...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>\"Outside of Heaven\" is a popular music song wh...</td>\n",
       "      <td>Eddie Fisher recorded the song \"Outside of Hea...</td>\n",
       "      <td>['the Unification Church']</td>\n",
       "      <td>['The Church of Scientology']</td>\n",
       "      <td>The query contains multiple components: (1) re...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>On what street was the hotel located where the...</td>\n",
       "      <td>On what street was the hotel located where the...</td>\n",
       "      <td>['Peachtree Street']</td>\n",
       "      <td>['South Virginia Street']</td>\n",
       "      <td>The query requires identifying a specific fire...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>What is the original name of the place where T...</td>\n",
       "      <td>What was the original name of the place in Min...</td>\n",
       "      <td>['Fort Saint Anthony']</td>\n",
       "      <td>['Fort Snelling']</td>\n",
       "      <td>The query seeks the 'original name' of the loc...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_question  \\\n",
       "0    In what year was the narrator of \"Blackadder's...   \n",
       "1    What is the first two words of the fifth studi...   \n",
       "2    Robert Earl Holding owned an oil company that ...   \n",
       "3               In what county was Duffy Jackson born?   \n",
       "4    When was the defending titlist of 2009–10 Biat...   \n",
       "..                                                 ...   \n",
       "319  The saint in \"A Time for Miracles\" was born on...   \n",
       "320  What is the name of the presidential memorial ...   \n",
       "321  \"Outside of Heaven\" is a popular music song wh...   \n",
       "322  On what street was the hotel located where the...   \n",
       "323  What is the original name of the place where T...   \n",
       "\n",
       "                                     modified_question  \\\n",
       "0    In what year was Hugh Laurie, who played Princ...   \n",
       "1    What are the first two words of the seventh st...   \n",
       "2    Robert Earl Holding owned Sinclair Oil Corpora...   \n",
       "3    In what county was the jazz drummer Duffy Jack...   \n",
       "4    When was the biathlete who was the reigning ov...   \n",
       "..                                                 ...   \n",
       "319  What is the birth date of the saint who is the...   \n",
       "320  What is the name of the presidential memorial ...   \n",
       "321  Eddie Fisher recorded the song \"Outside of Hea...   \n",
       "322  On what street was the hotel located where the...   \n",
       "323  What was the original name of the place in Min...   \n",
       "\n",
       "                   short_answer          model_original_answer  \\\n",
       "0                      ['1959']                       ['1949']   \n",
       "1                ['The Hungry']              ['The Patriotic']   \n",
       "2         ['Harry F. Sinclair']             ['David P. Smith']   \n",
       "3             ['Nassau County']             ['Suffolk County']   \n",
       "4           ['27 January 1974']             ['March 18, 1983']   \n",
       "..                          ...                            ...   \n",
       "319         ['August 28, 1774']          ['November 26, 1774']   \n",
       "320      ['Jefferson Memorial']  ['Thomas Jefferson Memorial']   \n",
       "321  ['the Unification Church']  ['The Church of Scientology']   \n",
       "322        ['Peachtree Street']      ['South Virginia Street']   \n",
       "323      ['Fort Saint Anthony']              ['Fort Snelling']   \n",
       "\n",
       "                                  classifier_reasoning  original_f1  \\\n",
       "0    The query seeks the birth year of the narrator...     0.000000   \n",
       "1    The query references 'Joseph Edgar Foreman,' w...     0.000000   \n",
       "2    The query requires determining the original fo...     0.000000   \n",
       "3    The query seeks information about the birth co...     0.500000   \n",
       "4    The query seeks the birth date of the 'defendi...     0.000000   \n",
       "..                                                 ...          ...   \n",
       "319  The query references 'A Time for Miracles,' a ...     0.333333   \n",
       "320  The query seeks a presidential memorial in Was...     0.800000   \n",
       "321  The query contains multiple components: (1) re...     0.400000   \n",
       "322  The query requires identifying a specific fire...     0.400000   \n",
       "323  The query seeks the 'original name' of the loc...     0.400000   \n",
       "\n",
       "     original_em  original_AA  \n",
       "0              0         0.00  \n",
       "1              0         0.00  \n",
       "2              0         0.00  \n",
       "3              0         0.00  \n",
       "4              0         0.00  \n",
       "..           ...          ...  \n",
       "319            0         0.00  \n",
       "320            0         0.50  \n",
       "321            0         0.00  \n",
       "322            0         0.00  \n",
       "323            0         0.25  \n",
       "\n",
       "[324 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_view = pd.DataFrame(question_modification)\n",
    "#df_view.to_csv(\"produced_files/modification_pilot.csv\")\n",
    "df_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060ea16",
   "metadata": {},
   "source": [
    "## Implementing QA on modified questions using GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50df210",
   "metadata": {},
   "source": [
    "### Loading GPT-4o and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b162f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://api.openai.com/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca3a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_short_answer(question, client, model=\"gpt-4o-2024-11-20\", temperature=0, max_retries=5, sleep_time=2.0):\n",
    "    system_prompt = (\n",
    "        \"Answer the question with a concise response. \"\n",
    "        \"Return answers as a list of strings. If there's only one answer, return a single-item list. \"\n",
    "        \"Each answer should be brief and direct.\"\n",
    "    )\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": question}\n",
    "                ],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            if content.startswith(\"[\"):\n",
    "                return eval(content)\n",
    "            else:\n",
    "                return [content.strip()]\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            time.sleep(sleep_time * retries)\n",
    "            \n",
    "    return [\"[Error]: Max retries exceeded\"]\n",
    "\n",
    "def run_batch_shortQA_api(batch, client, **kwargs):\n",
    "    short_answers = []\n",
    "    for q in batch[\"modified_question\"]:\n",
    "        try:\n",
    "            answer = ask_short_answer(q, client=client, **kwargs)\n",
    "            short_answers.append(answer)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            short_answers.append([\"error\"])\n",
    "    return {\"model_new_answer\": short_answers}\n",
    "\n",
    "def batch_QA_with_progress(dataset, batch_fn, output_key, batch_size=10, fill_value=\"error\", **batch_fn_kwargs):\n",
    "    all_outputs = []\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=f\"Running {output_key}\"):\n",
    "        batch = dataset.select(range(i, min(i + batch_size, len(dataset))))\n",
    "        try:\n",
    "            output = batch_fn(batch, **batch_fn_kwargs)\n",
    "            if output_key not in output:\n",
    "                raise ValueError(f\"Missing key '{output_key}' in batch result\")\n",
    "            all_outputs.extend(output[output_key])\n",
    "        except Exception as e:\n",
    "            print(f\"Batch error at {i}: {e}\")\n",
    "            all_outputs.extend([fill_value] * len(batch))\n",
    "\n",
    "    if len(all_outputs) != len(dataset):\n",
    "        print(f\"[Warning] Output length mismatch, auto-filling\")\n",
    "        all_outputs.extend([fill_value] * (len(dataset) - len(all_outputs)))\n",
    "\n",
    "    return {output_key: all_outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798df69",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651501df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805d38d12e8648b3b8719ee60c456355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modified_set = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_HotpotQA_UND_gpt_low_AA_samples_modified.jsonl\",\n",
    "    split=\"train\"  # 必须指定 split，否则默认返回 DatasetDict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6e4ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running model_new_answer: 100%|██████████| 33/33 [04:59<00:00,  9.09s/it]\n"
     ]
    }
   ],
   "source": [
    "modified_results = batch_QA_with_progress(\n",
    "    modified_set,\n",
    "    batch_fn=run_batch_shortQA_api,\n",
    "    output_key=\"model_new_answer\",\n",
    "    fill_value=[\"error\"],\n",
    "    client=client,\n",
    "    model=\"gpt-4o-2024-11-20\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b82e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33acdbed0044474fb383715738e7deff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question</th>\n",
       "      <th>modified_question</th>\n",
       "      <th>short_answer</th>\n",
       "      <th>model_original_answer</th>\n",
       "      <th>classifier_reasoning</th>\n",
       "      <th>original_f1</th>\n",
       "      <th>original_em</th>\n",
       "      <th>original_AA</th>\n",
       "      <th>model_new_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what year was the narrator of \"Blackadder's...</td>\n",
       "      <td>In what year was Hugh Laurie, who played Princ...</td>\n",
       "      <td>['1959']</td>\n",
       "      <td>['1949']</td>\n",
       "      <td>The query seeks the birth year of the narrator...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[1959]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the first two words of the fifth studi...</td>\n",
       "      <td>What are the first two words of the seventh st...</td>\n",
       "      <td>['The Hungry']</td>\n",
       "      <td>['The Patriotic']</td>\n",
       "      <td>The query references 'Joseph Edgar Foreman,' w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[The Patriotic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Earl Holding owned an oil company that ...</td>\n",
       "      <td>Robert Earl Holding owned Sinclair Oil Corpora...</td>\n",
       "      <td>['Harry F. Sinclair']</td>\n",
       "      <td>['David P. Smith']</td>\n",
       "      <td>The query requires determining the original fo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Harry F. Sinclair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what county was Duffy Jackson born?</td>\n",
       "      <td>In what county was the jazz drummer Duffy Jack...</td>\n",
       "      <td>['Nassau County']</td>\n",
       "      <td>['Suffolk County']</td>\n",
       "      <td>The query seeks information about the birth co...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Suffolk County]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When was the defending titlist of 2009–10 Biat...</td>\n",
       "      <td>When was the biathlete who was the reigning ov...</td>\n",
       "      <td>['27 January 1974']</td>\n",
       "      <td>['March 18, 1983']</td>\n",
       "      <td>The query seeks the birth date of the 'defendi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[March 27, 1983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>The saint in \"A Time for Miracles\" was born on...</td>\n",
       "      <td>What is the birth date of the saint who is the...</td>\n",
       "      <td>['August 28, 1774']</td>\n",
       "      <td>['November 26, 1774']</td>\n",
       "      <td>The query references 'A Time for Miracles,' a ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[November 26, 1774]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>What is the name of the presidential memorial ...</td>\n",
       "      <td>What is the name of the presidential memorial ...</td>\n",
       "      <td>['Jefferson Memorial']</td>\n",
       "      <td>['Thomas Jefferson Memorial']</td>\n",
       "      <td>The query seeks a presidential memorial in Was...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[Thomas Jefferson Memorial]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>\"Outside of Heaven\" is a popular music song wh...</td>\n",
       "      <td>Eddie Fisher recorded the song \"Outside of Hea...</td>\n",
       "      <td>['the Unification Church']</td>\n",
       "      <td>['The Church of Scientology']</td>\n",
       "      <td>The query contains multiple components: (1) re...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[The New Yorker Hotel was purchased in 1976 fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>On what street was the hotel located where the...</td>\n",
       "      <td>On what street was the hotel located where the...</td>\n",
       "      <td>['Peachtree Street']</td>\n",
       "      <td>['South Virginia Street']</td>\n",
       "      <td>The query requires identifying a specific fire...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Peachtree Street]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>What is the original name of the place where T...</td>\n",
       "      <td>What was the original name of the place in Min...</td>\n",
       "      <td>['Fort Saint Anthony']</td>\n",
       "      <td>['Fort Snelling']</td>\n",
       "      <td>The query seeks the 'original name' of the loc...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[Fort Snelling]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_question  \\\n",
       "0    In what year was the narrator of \"Blackadder's...   \n",
       "1    What is the first two words of the fifth studi...   \n",
       "2    Robert Earl Holding owned an oil company that ...   \n",
       "3               In what county was Duffy Jackson born?   \n",
       "4    When was the defending titlist of 2009–10 Biat...   \n",
       "..                                                 ...   \n",
       "319  The saint in \"A Time for Miracles\" was born on...   \n",
       "320  What is the name of the presidential memorial ...   \n",
       "321  \"Outside of Heaven\" is a popular music song wh...   \n",
       "322  On what street was the hotel located where the...   \n",
       "323  What is the original name of the place where T...   \n",
       "\n",
       "                                     modified_question  \\\n",
       "0    In what year was Hugh Laurie, who played Princ...   \n",
       "1    What are the first two words of the seventh st...   \n",
       "2    Robert Earl Holding owned Sinclair Oil Corpora...   \n",
       "3    In what county was the jazz drummer Duffy Jack...   \n",
       "4    When was the biathlete who was the reigning ov...   \n",
       "..                                                 ...   \n",
       "319  What is the birth date of the saint who is the...   \n",
       "320  What is the name of the presidential memorial ...   \n",
       "321  Eddie Fisher recorded the song \"Outside of Hea...   \n",
       "322  On what street was the hotel located where the...   \n",
       "323  What was the original name of the place in Min...   \n",
       "\n",
       "                   short_answer          model_original_answer  \\\n",
       "0                      ['1959']                       ['1949']   \n",
       "1                ['The Hungry']              ['The Patriotic']   \n",
       "2         ['Harry F. Sinclair']             ['David P. Smith']   \n",
       "3             ['Nassau County']             ['Suffolk County']   \n",
       "4           ['27 January 1974']             ['March 18, 1983']   \n",
       "..                          ...                            ...   \n",
       "319         ['August 28, 1774']          ['November 26, 1774']   \n",
       "320      ['Jefferson Memorial']  ['Thomas Jefferson Memorial']   \n",
       "321  ['the Unification Church']  ['The Church of Scientology']   \n",
       "322        ['Peachtree Street']      ['South Virginia Street']   \n",
       "323      ['Fort Saint Anthony']              ['Fort Snelling']   \n",
       "\n",
       "                                  classifier_reasoning  original_f1  \\\n",
       "0    The query seeks the birth year of the narrator...     0.000000   \n",
       "1    The query references 'Joseph Edgar Foreman,' w...     0.000000   \n",
       "2    The query requires determining the original fo...     0.000000   \n",
       "3    The query seeks information about the birth co...     0.500000   \n",
       "4    The query seeks the birth date of the 'defendi...     0.000000   \n",
       "..                                                 ...          ...   \n",
       "319  The query references 'A Time for Miracles,' a ...     0.333333   \n",
       "320  The query seeks a presidential memorial in Was...     0.800000   \n",
       "321  The query contains multiple components: (1) re...     0.400000   \n",
       "322  The query requires identifying a specific fire...     0.400000   \n",
       "323  The query seeks the 'original name' of the loc...     0.400000   \n",
       "\n",
       "     original_em  original_AA  \\\n",
       "0              0         0.00   \n",
       "1              0         0.00   \n",
       "2              0         0.00   \n",
       "3              0         0.00   \n",
       "4              0         0.00   \n",
       "..           ...          ...   \n",
       "319            0         0.00   \n",
       "320            0         0.50   \n",
       "321            0         0.00   \n",
       "322            0         0.00   \n",
       "323            0         0.25   \n",
       "\n",
       "                                      model_new_answer  \n",
       "0                                               [1959]  \n",
       "1                                      [The Patriotic]  \n",
       "2                                  [Harry F. Sinclair]  \n",
       "3                                     [Suffolk County]  \n",
       "4                                     [March 27, 1983]  \n",
       "..                                                 ...  \n",
       "319                                [November 26, 1774]  \n",
       "320                        [Thomas Jefferson Memorial]  \n",
       "321  [The New Yorker Hotel was purchased in 1976 fo...  \n",
       "322                                 [Peachtree Street]  \n",
       "323                                    [Fort Snelling]  \n",
       "\n",
       "[324 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_modified = deepcopy(modified_set)\n",
    "for key in modified_results:\n",
    "    qa_modified = qa_modified.add_column(key, modified_results[key])\n",
    "\n",
    "qa_modified.to_json(\"BASELINE_HotpotQA_UND_gpt_low_AA_samples_modified.jsonl\", orient=\"records\", lines=True)\n",
    "df_qa_modified = pd.read_json(\"BASELINE_HotpotQA_UND_gpt_low_AA_samples_modified.jsonl\", lines=True)\n",
    "#df_qa_modified.to_csv('produced_files/modification_pilot_qa.csv')\n",
    "df_qa_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904edcd",
   "metadata": {},
   "source": [
    "### Traditional Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac915dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_squad_per_sample_multi_ref_pred(dataset, pred_col=\"model_new_answer\", ref_col=\"short_answer\"):\n",
    "    \"\"\"\n",
    "    对每个样本逐一计算 EM 和 F1，支持多个参考答案和多个预测答案（list[str]）。\n",
    "    返回带 \"em\", \"f1\" 列的新 Dataset，以及 f1/em 列表用于统计分析。\n",
    "    Also considering multiple answers in both gold and pred and take the maximum score\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize_answer(s):\n",
    "        def remove_articles(text):\n",
    "            return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "        def white_space_fix(text):\n",
    "            return ' '.join(text.split())\n",
    "        def remove_punc(text):\n",
    "            return ''.join(ch for ch in text if ch not in string.punctuation)\n",
    "        def lower(text):\n",
    "            return text.lower()\n",
    "        return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "    def compute_exact(a_pred, a_gold):\n",
    "    # 如果是 list，转成 set 并 normalize 每个元素\n",
    "        if isinstance(a_pred, list) and isinstance(a_gold, list):\n",
    "          pred_set = set(normalize_answer(a) for a in a_pred)\n",
    "          gold_set = set(normalize_answer(a) for a in a_gold)\n",
    "          return int(pred_set == gold_set)\n",
    "        else:\n",
    "          return int(normalize_answer(a_pred) == normalize_answer(a_gold))\n",
    "\n",
    "    def compute_f1(a_pred, a_gold):\n",
    "        pred_tokens = normalize_answer(a_pred).split()\n",
    "        gold_tokens = normalize_answer(a_gold).split()\n",
    "        common = Counter(pred_tokens) & Counter(gold_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            return 0.0\n",
    "        precision = num_same / len(pred_tokens)\n",
    "        recall = num_same / len(gold_tokens)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    new_data = []\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "\n",
    "    for item in dataset:\n",
    "        preds = item.get(pred_col, [])\n",
    "        golds = item.get(ref_col, [])\n",
    "        # 转为 list\n",
    "        if not isinstance(preds, list):\n",
    "            preds = [preds] if preds else []\n",
    "        if not isinstance(golds, list):\n",
    "            golds = [golds] if golds else []\n",
    "\n",
    "        # 多对多最大匹配\n",
    "        if not preds or not golds:\n",
    "            em = 0.0\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            em = max(compute_exact(p, g) for p in preds for g in golds)\n",
    "            f1 = max(compute_f1(p, g) for p in preds for g in golds)\n",
    "\n",
    "        new_item = deepcopy(item)\n",
    "        new_item[\"new_em\"] = em\n",
    "        new_item[\"new_f1\"] = f1\n",
    "        new_data.append(new_item)\n",
    "        em_scores.append(em)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return Dataset.from_list(new_data), f1_scores, em_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a1574b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767127acd8a24bc5b5b303974f01bb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad_scored_modified, modified_f1_list, modified_em_list = evaluate_squad_per_sample_multi_ref_pred(qa_modified)\n",
    "squad_scored_modified.to_json(\"BASELINE_HotpotQA_Gemini_modified_GPT_qa_squad_scores.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "df = pd.read_json(\"BASELINE_HotpotQA_Gemini_modified_GPT_qa_squad_scores.jsonl\", lines=True)\n",
    "df.to_csv('BASELINE_HotpotQA_Gemini_modified_GPT_qa_squad_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e218902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New answers after modification Exact Match (avg): 24.69\n",
      "New answers after modification F1 Score (avg): 42.64\n",
      "Original answers Exact Match (avg): 0.00\n",
      "Original answers F1 Score (avg): 10.71\n",
      "F1: t=12.781, p=0.0000\n",
      "EM: t=10.291, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "modified_mean_em = np.mean(modified_em_list)  # em_scores: EM list per sample\n",
    "modified_mean_f1 = np.mean(modified_f1_list)  # f1_scores F1 list per sample\n",
    "print(f\"New answers after modification Exact Match (avg): {modified_mean_em * 100:.2f}\")\n",
    "print(f\"New answers after modification F1 Score (avg): {modified_mean_f1 * 100:.2f}\")\n",
    "\n",
    "original_em_list = qa_modified['original_em']\n",
    "original_f1_list = qa_modified['original_f1']\n",
    "\n",
    "original_mean_em = np.mean(original_em_list)  # em_scores: EM list per sample\n",
    "original_mean_f1 = np.mean(original_f1_list)  # f1_scores F1 list per sample\n",
    "print(f\"Original answers Exact Match (avg): {original_mean_em * 100:.2f}\")\n",
    "print(f\"Original answers F1 Score (avg): {original_mean_f1 * 100:.2f}\")\n",
    "\n",
    "f1_tstat, f1_pval = ttest_ind(modified_f1_list, original_f1_list, equal_var=False)\n",
    "print(f\"F1: t={f1_tstat:.3f}, p={f1_pval:.4f}\")\n",
    "\n",
    "em_tstat, em_pval = ttest_ind(modified_em_list, original_em_list, equal_var=False)\n",
    "print(f\"EM: t={em_tstat:.3f}, p={em_pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb9e3d",
   "metadata": {},
   "source": [
    "### Ragas AA evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a588426",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(ChatDeepSeek(model=\"deepseek-chat\", verbose=True, temperature=0))\n",
    "\n",
    "async def answer_accuracy_modified(input_dataset, evaluator=evaluator_llm):\n",
    "    # 在函数开始时创建一次 scorer\n",
    "    scorer = AnswerAccuracy(llm=evaluator)\n",
    "    \n",
    "\n",
    "    score_list = []\n",
    "        \n",
    "    for i, row in enumerate(tqdm(input_dataset, desc=\"Calculating short answer accuracy\")):\n",
    "        try:\n",
    "            # 短答案评分 - 处理列表情况\n",
    "            if 'short_answer' in row and 'model_new_answer' in row:\n",
    "                model_answers = row['model_new_answer'] if isinstance(row['model_new_answer'], list) else [row['model_new_answer']]\n",
    "                reference_answers = row['short_answer'] if isinstance(row['short_answer'], list) else [row['short_answer']]\n",
    "                    \n",
    "                # 计算所有组合的分数，取最高分\n",
    "                max_score = 0.0\n",
    "                for model_ans in model_answers:\n",
    "                    for ref_ans in reference_answers:\n",
    "                        sample = SingleTurnSample(\n",
    "                                user_input=row['modified_question'],\n",
    "                                response=model_ans,\n",
    "                                reference=ref_ans\n",
    "                            )\n",
    "                        score = await scorer.single_turn_ascore(sample)\n",
    "                        max_score = max(max_score, score)\n",
    "                        if max_score == 1.0:\n",
    "                            break  # 跳出内层循环\n",
    "                    if max_score == 1.0:\n",
    "                        break  # 跳出外层循环\n",
    "                \n",
    "                score_list.append(max_score)\n",
    "            else:\n",
    "                score_list.append(0.0)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"处理第 {i+1} 个样本时出错: {e}\")\n",
    "            score_list.append(0.0)\n",
    "\n",
    "    ragas_scored_dataset = input_dataset.add_column(\"new_AA\", score_list)\n",
    "\n",
    "    return ragas_scored_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c358db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeacd06d4f348a3904e6fbca7ae6e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating short answer accuracy: 100%|██████████| 324/324 [47:52<00:00,  8.86s/it] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a822006002842be99ed03133e32acac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "313936"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_scored_modified = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_HotpotQA_Gemini_modified_GPT_qa_squad_scores.jsonl\",\n",
    "    split=\"train\")\n",
    "result_with_AA = await answer_accuracy_modified(squad_scored_modified)\n",
    "result_with_AA.to_csv(\"BASELINE_HotpotQA_Gemini_modified_GPT_qa_all_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfedc5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original AA (avg): 11.50\n",
      "modified AA (avg): 48.23\n",
      "AA: t=13.003, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "original_AA = list(result_with_AA[\"original_AA\"])\n",
    "modified_AA = list(result_with_AA[\"new_AA\"])\n",
    "\n",
    "original_mean_AA = np.mean(original_AA)\n",
    "print(f\"original AA (avg): {original_mean_AA * 100:.2f}\")\n",
    "\n",
    "\n",
    "modified_mean_AA = np.mean(modified_AA)\n",
    "print(f\"modified AA (avg): {modified_mean_AA * 100:.2f}\")\n",
    "\n",
    "AA_tstat, AA_pval = ttest_ind(modified_AA, original_AA, equal_var=False)\n",
    "print(f\"AA: t={AA_tstat:.3f}, p={AA_pval:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

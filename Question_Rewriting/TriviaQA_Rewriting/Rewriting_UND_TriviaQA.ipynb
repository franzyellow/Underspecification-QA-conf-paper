{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8393de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "from typing import List, Literal, List, Dict, Any\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy import LabeledFewShot\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from functools import partial\n",
    "from datasets import Dataset\n",
    "from copy import deepcopy\n",
    "import evaluate\n",
    "import nltk\n",
    "from scipy.stats import ttest_ind\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import AnswerAccuracy\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf755b0",
   "metadata": {},
   "source": [
    "## RAGAS-AA filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b44cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_low_AA_samples(input_file, output_file, threshold):\n",
    "    \"\"\"\n",
    "    Randomly extract specified number of samples with low f1 score from JSONL file\n",
    "    \n",
    "    Args:\n",
    "        input_file: Input JSONL file path\n",
    "        output_file: Output JSONL file path\n",
    "    \"\"\"\n",
    "    target_samples = []\n",
    "    \n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            if data.get('ragas_AA_short') < threshold:\n",
    "                target_samples.append(data)\n",
    "    \n",
    "    print(f\"Found {len(target_samples)} samples satisfying the defined condition\")\n",
    "    \n",
    "    # Write to new JSONL file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for sample in target_samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"Successfully extracted {len(target_samples)} samples with Ragas AA <= {threshold} to {output_file}\")\n",
    "    return target_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae57fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68d8289aa35412791b36e3aa9cb1fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../baseline_classifier_for_paper/TriviaQA_UND_gpt4o_Ragas.csv\")\n",
    "df.to_json(\"BASELINE_TriviaQA_UND_gpt4o_Ragas.jsonl\", orient=\"records\", lines=True)\n",
    "dataset = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_TriviaQA_UND_gpt4o_Ragas.jsonl\",\n",
    "    split=\"train\"  # 必须指定 split，否则默认返回 DatasetDict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4718204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 samples satisfying the defined condition\n",
      "Successfully extracted 29 samples with Ragas AA <= 1 to BASELINE_TriviaQA_UND_gpt4o_Ragas_low_AA.jsonl\n"
     ]
    }
   ],
   "source": [
    "input_file = \"BASELINE_TriviaQA_UND_gpt4o_Ragas.jsonl\"\n",
    "output_file = \"BASELINE_TriviaQA_UND_gpt4o_Ragas_low_AA.jsonl\"\n",
    "target_samples = retrieve_all_low_AA_samples(input_file, output_file, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac26f06",
   "metadata": {},
   "source": [
    "## Rewriting with Gemini-2.5-Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db960c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "def modify_question_with_gemini(question, short_answer, reasoning, model=\"gemini-2.5-flash\", temperature=0, max_retries=5, sleep_time=2.0):\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a professional question optimization expert. Please modify the underspecified question to a fully specified version based on the provided clues.\\n\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"1. Keep the core intent of the question unchanged\\n\"\n",
    "        \"2. Add necessary contextual information\\n\"\n",
    "        \"3. Eliminate underspecified elements and make the question clear\\n\"\n",
    "        \"4. Ensure the modified question can be directly answered with the provided short answer without dispute\\n\\n\"\n",
    "        \"Please only return the modified question, do not include any other explanations.\"\n",
    "    )\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "The original question: {question}\n",
    "Short answer: {short_answer}\n",
    "Reasoning: {reasoning}\n",
    "\n",
    "Please analyze the underspecified elements in the original question, then modify the question to a fully specified version based on the short answer and reasoning.\n",
    "\"\"\"\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            modified_question = content.strip()\n",
    "            return modified_question\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Attempt {retries} failed: {str(e)}\")\n",
    "            if retries < max_retries:\n",
    "                print(f\"Waiting {sleep_time * retries} seconds before retry...\")\n",
    "                time.sleep(sleep_time * retries)\n",
    "            else:\n",
    "                print(f\"All retries failed, returning original question\")\n",
    "                return question  # If error occurs, return original question\n",
    "\n",
    "def modification_in_batch_alt(input_file, output_file, ref_col, batch_size=5):\n",
    "    \"\"\"\n",
    "    按批次处理所有样本，提高处理效率\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入JSONL文件路径\n",
    "        output_file: 输出JSONL文件路径\n",
    "        batch_size: 每批处理的样本数量\n",
    "    \n",
    "    Returns:\n",
    "        list: 所有处理过的样本\n",
    "    \"\"\"\n",
    "    \n",
    "    all_processed_samples = []\n",
    "    \n",
    "    # Loading all the data from the input file\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    total_samples = len(lines)\n",
    "    print(f\"Total samples to process: {total_samples}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    # Process all samples in batches\n",
    "    for batch_start in tqdm(range(0, total_samples, batch_size), desc=\"Processing batches\"):\n",
    "        batch_end = min(batch_start + batch_size, total_samples)\n",
    "        batch_lines = lines[batch_start:batch_end]\n",
    "        \n",
    "        batch_processed_samples = []\n",
    "        \n",
    "        # Process each sample in the current batch\n",
    "        for i, line in enumerate(batch_lines):\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                \n",
    "                # Extract necessary fields\n",
    "                question = data['question']\n",
    "                short_answer = data[ref_col]\n",
    "                classifier_response = data['qwen3_model_response']\n",
    "                classifier_reasoning = json.loads(classifier_response)['reasoning']\n",
    "                \n",
    "                # Modify questions\n",
    "                modified_question = modify_question_with_gemini(question, short_answer, classifier_reasoning)\n",
    "                \n",
    "                # Create new data structure\n",
    "                new_sample = {\n",
    "                    'original_question': question,\n",
    "                    'modified_question': modified_question,\n",
    "                    'short_answer': short_answer,\n",
    "                    'model_original_answer': data.get('model_short_answer', 'undefined'),\n",
    "                    'classifier_reasoning': classifier_reasoning,\n",
    "                    'original_f1': data.get('f1', 'undefined'),\n",
    "                    'original_em': data.get('em', 'undefined'),\n",
    "                    'original_AA': data.get('ragas_AA_short', 'undefined')\n",
    "                }\n",
    "                \n",
    "                batch_processed_samples.append(new_sample)\n",
    "                \n",
    "                # Add delay to avoid API rate limits\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {batch_start + i + 1}: {e}\")\n",
    "                # Create error sample to maintain consistency\n",
    "                error_sample = {\n",
    "                    'original_question': question,\n",
    "                    'modified_question': modified_question,\n",
    "                    'short_answer': short_answer,\n",
    "                    'model_original_answer': data.get('model_short_answer', 'error'),\n",
    "                    'classifier_reasoning': classifier_reasoning,\n",
    "                    'original_f1': data.get('f1', 'error'),\n",
    "                    'original_em': data.get('em', 'error'),\n",
    "                    'original_AA': data.get('ragas_AA_short', 'error')\n",
    "                }\n",
    "                batch_processed_samples.append(error_sample)\n",
    "        \n",
    "        # Add batch results to all processed samples\n",
    "        all_processed_samples.extend(batch_processed_samples)\n",
    "        \n",
    "        # Write intermediate results to file (append mode)\n",
    "        with open(output_file, 'a', encoding='utf-8') as f:\n",
    "            for sample in batch_processed_samples:\n",
    "                f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "    \n",
    "    print(f\"\\nAll batch processing completed! Total processed: {len(all_processed_samples)} samples\")\n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    return all_processed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25633f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples to process: 29\n",
      "Batch size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 10/10 [10:50<00:00, 65.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All batch processing completed! Total processed: 29 samples\n",
      "Results saved to: BASELINE_TriviaQA_UND_gpt_low_AA_samples_modified.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 清空输出文件（如果存在）\n",
    "modified_output_file = \"BASELINE_TriviaQA_UND_gpt_low_AA_samples_modified.jsonl\"\n",
    "if os.path.exists(modified_output_file):\n",
    "    os.remove(modified_output_file)\n",
    "    print(f\"Cleared existing output file: {modified_output_file}\")\n",
    "\n",
    "# 处理所有样本（按批次）\n",
    "question_modification = modification_in_batch_alt(output_file, modified_output_file, ref_col='normalized_aliases', batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add4ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 查找失败的行（简单方法）===\n",
      "发现 0 个失败的行:\n"
     ]
    }
   ],
   "source": [
    "def find_failed_rows_simple(input_file, output_file):\n",
    "    \"\"\"\n",
    "    简单方法：通过比较原问题和修改后问题是否相同来找出失败的行\n",
    "    \"\"\"\n",
    "    print(\"=== 查找失败的行（简单方法）===\")\n",
    "    \n",
    "    # 读取输入和输出文件\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        input_data = [json.loads(line.strip()) for line in f]\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        output_data = [json.loads(line.strip()) for line in f]\n",
    "    \n",
    "    failed_rows = []\n",
    "    \n",
    "    for i, (input_row, output_row) in enumerate(zip(input_data, output_data)):\n",
    "        original_question = input_row.get('question', '')\n",
    "        modified_question = output_row.get('modified_question', '')\n",
    "        \n",
    "        # 如果原问题和修改后问题相同，说明失败了\n",
    "        if original_question == modified_question:\n",
    "            failed_rows.append({\n",
    "                'row_number': i + 1,\n",
    "                'original_question': original_question,\n",
    "                'short_answer': input_row.get('short_answers', ''),\n",
    "                'reasoning': input_row.get('reasoning', '')\n",
    "            })\n",
    "    \n",
    "    print(f\"发现 {len(failed_rows)} 个失败的行:\")\n",
    "    for row in failed_rows:\n",
    "        print(f\"\\n第 {row['row_number']} 行:\")\n",
    "        print(f\"  问题: {row['original_question'][:100]}...\")\n",
    "        print(f\"  短答案: {row['short_answer']}\")\n",
    "        print(f\"  推理: {row['reasoning'][:100]}...\")\n",
    "    \n",
    "    return failed_rows\n",
    "\n",
    "# 使用简单方法查找失败的行\n",
    "failed_rows = find_failed_rows_simple(\n",
    "    \"BASELINE_TriviaQA_UND_gpt4o_Ragas_low_AA.jsonl\",\n",
    "    \"BASELINE_TriviaQA_UND_gpt_low_AA_samples_modified.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb725e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question</th>\n",
       "      <th>modified_question</th>\n",
       "      <th>short_answer</th>\n",
       "      <th>model_original_answer</th>\n",
       "      <th>classifier_reasoning</th>\n",
       "      <th>original_f1</th>\n",
       "      <th>original_em</th>\n",
       "      <th>original_AA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When Mr Benn was looking for an adventure, wha...</td>\n",
       "      <td>In the children's animated series 'Mr Benn', w...</td>\n",
       "      <td>['fancy dress shop']</td>\n",
       "      <td>['A costume shop']</td>\n",
       "      <td>The query references 'Mr Benn,' a name that do...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which company produced the Hastings and Herald...</td>\n",
       "      <td>Which British company produced the Handley Pag...</td>\n",
       "      <td>['handley page aircraft company' 'o 100 and o ...</td>\n",
       "      <td>['Miles Aircraft']</td>\n",
       "      <td>The query asks for the manufacturer of two air...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the Queen's horses won the 2013 Ascot...</td>\n",
       "      <td>Considering historical records do not substant...</td>\n",
       "      <td>['estimating' 'estimated' 'estimate' 'overesti...</td>\n",
       "      <td>['Estimate']</td>\n",
       "      <td>The query hinges on two potentially ambiguous ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The expression 'Go West' originally (mid-1800s...</td>\n",
       "      <td>The expression 'Go West' originally (mid-1800s...</td>\n",
       "      <td>['u s of america' 'u–s–' 'estatos unitos' 'ama...</td>\n",
       "      <td>['Within']</td>\n",
       "      <td>The query seeks clarification on the geographi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which month of the year came second in the Rom...</td>\n",
       "      <td>Which month was the second in the ancient Roma...</td>\n",
       "      <td>['㋃' 'april month' 'april' 'aprill' 'cruellest...</td>\n",
       "      <td>['February']</td>\n",
       "      <td>The query asks for the second month in the 'Ro...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How many ‘Triangles’ are there on the logo of ...</td>\n",
       "      <td>How many distinct colored sections, which are ...</td>\n",
       "      <td>['four' '4']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>The BMW logo features three interlocked circle...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who created the ‘A’ Line in 1955?</td>\n",
       "      <td>Who created the 'A' Line fashion collection in...</td>\n",
       "      <td>['jacques benita' 'dior monsieur' 'christian d...</td>\n",
       "      <td>['Cristóbal Balenciaga']</td>\n",
       "      <td>The query contains three key components: the s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chi is the Chinese year of what?</td>\n",
       "      <td>What is the Chinese zodiac animal for the year...</td>\n",
       "      <td>['cock' 'cock disambiguation' 'cocks']</td>\n",
       "      <td>[\"Chi is not directly associated with a specif...</td>\n",
       "      <td>The query appears to ask for the Chinese zodia...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toothpaste, turtle, oxblood, oilie/oily, ade, ...</td>\n",
       "      <td>Toothpaste, turtle, oxblood, oilie/oily, ade, ...</td>\n",
       "      <td>['goti marbles in hindi' 'aggie marble' 'marbl...</td>\n",
       "      <td>['Nail polish finishes or textures']</td>\n",
       "      <td>The query asks for a categorization of multipl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give a year in the life of Irish playwright an...</td>\n",
       "      <td>What are the birth and death years of Irish pl...</td>\n",
       "      <td>['1871 1909']</td>\n",
       "      <td>['1871']</td>\n",
       "      <td>The query requests 'a year in the life' of Joh...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When was the current theme for the BBC televis...</td>\n",
       "      <td>When was the iconic theme tune 'Jessica' by Th...</td>\n",
       "      <td>['one thousand nine hundred and seventy three'...</td>\n",
       "      <td>['1981']</td>\n",
       "      <td>The query is underspecified due to several amb...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What word links take, write and stand</td>\n",
       "      <td>Identify the single word that functions as a p...</td>\n",
       "      <td>['under' 'under disambiguation']</td>\n",
       "      <td>['Up']</td>\n",
       "      <td>The query seeks a single word that 'links' the...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What US sitcom was the first exported to Britain?</td>\n",
       "      <td>What US sitcom was the first to be broadcast b...</td>\n",
       "      <td>['amos andy' 'brazilian brass mines' 'george 2...</td>\n",
       "      <td>['I Love Lucy']</td>\n",
       "      <td>The query asks for a specific historical claim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Who wrote the piece of music recognised in mu...</td>\n",
       "      <td>Who composed the 'Wedding March' that is part ...</td>\n",
       "      <td>['felix mendelssohn' 'mendelsson bartholdy' 'f...</td>\n",
       "      <td>['Richard Wagner']</td>\n",
       "      <td>The query asks about the author of a piece kno...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>To which species does the Gnu or Wildebeest be...</td>\n",
       "      <td>To what type of animal does the Gnu or Wildebe...</td>\n",
       "      <td>['antelope case' '23 u s 66' 'antelope'\\n 'ant...</td>\n",
       "      <td>['Connochaetes']</td>\n",
       "      <td>The query asks about the species classificatio...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'Cape Cod Salad' is an exotic summer dish centred</td>\n",
       "      <td>'Cape Cod Salad' is an exotic summer dish cent...</td>\n",
       "      <td>['lobster']</td>\n",
       "      <td>['Cape Cod Salad is an exotic summer dish cent...</td>\n",
       "      <td>The query mentions 'Cape Cod Salad' as an 'exo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What holiday is particularly associated with M...</td>\n",
       "      <td>Which traditional Christian holiday, historica...</td>\n",
       "      <td>['whitsuntide' 'whitsun' 'whit sunday' 'whitsu...</td>\n",
       "      <td>['May Day']</td>\n",
       "      <td>The query asks for a holiday closely linked to...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Poopdeck Pappy is which fictional character’s ...</td>\n",
       "      <td>In the 'Popeye' comic strip and animated serie...</td>\n",
       "      <td>['popeye and olive oyl show' 'thimble theatre'...</td>\n",
       "      <td>['Popeye']</td>\n",
       "      <td>The query seeks to identify a fictional charac...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What colour jumper does fictional character Ru...</td>\n",
       "      <td>What colour coat does Rupert the Bear wear in ...</td>\n",
       "      <td>['red colour' 'incarnadined' 'reddened' 'aztec...</td>\n",
       "      <td>['Yellow']</td>\n",
       "      <td>The query references 'Rupert the Bear,' a well...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pancetta is a type of what?</td>\n",
       "      <td>Pancetta is a type of what, commonly known as ...</td>\n",
       "      <td>['hickory bacon' 'side bacon' 'back rashers' '...</td>\n",
       "      <td>['Cured meat']</td>\n",
       "      <td>The query asks for the broader category or cla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A Paris grocer was jailed for two years in 197...</td>\n",
       "      <td>A Paris grocer was jailed for two years in 197...</td>\n",
       "      <td>['wedge of hard cheese']</td>\n",
       "      <td>['For stabbing his wife to death.']</td>\n",
       "      <td>The query contains critical gaps and ambiguiti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Whose 1995 best seller argues that our univers...</td>\n",
       "      <td>Whose 1995 best seller argues that our univers...</td>\n",
       "      <td>['steven hawkins' 'stephen hawking' 'stephan h...</td>\n",
       "      <td>['Paul Davies']</td>\n",
       "      <td>The query specifies three critical pieces of i...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'Cape Cod Salad' is an exotic summer dish centred</td>\n",
       "      <td>What key ingredient is 'Cape Cod Salad', an ex...</td>\n",
       "      <td>['lobster']</td>\n",
       "      <td>['Cape Cod Salad is centered around fresh ingr...</td>\n",
       "      <td>The query appears to be incomplete, ending abr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>In Japan, what is a hibachi used for?</td>\n",
       "      <td>In Japan, what is the hibachi (heating applian...</td>\n",
       "      <td>['cooking methods' 'cookery' 'par cooked' 'coo...</td>\n",
       "      <td>['A hibachi is used as a small heating device ...</td>\n",
       "      <td>The term 'hibachi' refers to at least two dist...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Are you going to come quietly, or do I have to...</td>\n",
       "      <td>Who is known for saying, \"Are you going to com...</td>\n",
       "      <td>['terence alan patrick seán milligan'\\n 'teren...</td>\n",
       "      <td>['This is a humorous or rhetorical question, o...</td>\n",
       "      <td>The query contains metaphorical language and a...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Macbeth belonged to which royal house or dynasty?</td>\n",
       "      <td>To which royal house or dynasty did Malcolm II...</td>\n",
       "      <td>['macmalcolm' 'canmore dynasty' 'canmores' 'du...</td>\n",
       "      <td>['House of Alpin']</td>\n",
       "      <td>The query asks about Macbeth's royal affiliati...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How many pints are there in a 'Winchester'?</td>\n",
       "      <td>What is the numerical designation of the New Z...</td>\n",
       "      <td>['four' 'four tv channel nz' 'four new zealand...</td>\n",
       "      <td>['A Winchester bushel contains 64 pints.']</td>\n",
       "      <td>'Winchester' is not a standardized unit of mea...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The books 'The Edge of Reason' and 'Mad About ...</td>\n",
       "      <td>The books 'Bridget Jones: The Edge of Reason' ...</td>\n",
       "      <td>['bridget joneses diary' 'bridget jones diary'...</td>\n",
       "      <td>['[Error]: Max retries exceeded']</td>\n",
       "      <td>The query asks for a single novel that both 'T...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Motor Racing. Which team has announced that th...</td>\n",
       "      <td>Motor Racing. Which team announced its withdra...</td>\n",
       "      <td>['bmw z2' 'bavarian motor works' 'bayerische m...</td>\n",
       "      <td>['Honda']</td>\n",
       "      <td>The query seeks information about a specific t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_question  \\\n",
       "0   When Mr Benn was looking for an adventure, wha...   \n",
       "1   Which company produced the Hastings and Herald...   \n",
       "2   Which of the Queen's horses won the 2013 Ascot...   \n",
       "3   The expression 'Go West' originally (mid-1800s...   \n",
       "4   Which month of the year came second in the Rom...   \n",
       "5   How many ‘Triangles’ are there on the logo of ...   \n",
       "6                   Who created the ‘A’ Line in 1955?   \n",
       "7                    Chi is the Chinese year of what?   \n",
       "8   Toothpaste, turtle, oxblood, oilie/oily, ade, ...   \n",
       "9   Give a year in the life of Irish playwright an...   \n",
       "10  When was the current theme for the BBC televis...   \n",
       "11              What word links take, write and stand   \n",
       "12  What US sitcom was the first exported to Britain?   \n",
       "13  \"Who wrote the piece of music recognised in mu...   \n",
       "14  To which species does the Gnu or Wildebeest be...   \n",
       "15  'Cape Cod Salad' is an exotic summer dish centred   \n",
       "16  What holiday is particularly associated with M...   \n",
       "17  Poopdeck Pappy is which fictional character’s ...   \n",
       "18  What colour jumper does fictional character Ru...   \n",
       "19                        Pancetta is a type of what?   \n",
       "20  A Paris grocer was jailed for two years in 197...   \n",
       "21  Whose 1995 best seller argues that our univers...   \n",
       "22  'Cape Cod Salad' is an exotic summer dish centred   \n",
       "23              In Japan, what is a hibachi used for?   \n",
       "24  Are you going to come quietly, or do I have to...   \n",
       "25  Macbeth belonged to which royal house or dynasty?   \n",
       "26        How many pints are there in a 'Winchester'?   \n",
       "27  The books 'The Edge of Reason' and 'Mad About ...   \n",
       "28  Motor Racing. Which team has announced that th...   \n",
       "\n",
       "                                    modified_question  \\\n",
       "0   In the children's animated series 'Mr Benn', w...   \n",
       "1   Which British company produced the Handley Pag...   \n",
       "2   Considering historical records do not substant...   \n",
       "3   The expression 'Go West' originally (mid-1800s...   \n",
       "4   Which month was the second in the ancient Roma...   \n",
       "5   How many distinct colored sections, which are ...   \n",
       "6   Who created the 'A' Line fashion collection in...   \n",
       "7   What is the Chinese zodiac animal for the year...   \n",
       "8   Toothpaste, turtle, oxblood, oilie/oily, ade, ...   \n",
       "9   What are the birth and death years of Irish pl...   \n",
       "10  When was the iconic theme tune 'Jessica' by Th...   \n",
       "11  Identify the single word that functions as a p...   \n",
       "12  What US sitcom was the first to be broadcast b...   \n",
       "13  Who composed the 'Wedding March' that is part ...   \n",
       "14  To what type of animal does the Gnu or Wildebe...   \n",
       "15  'Cape Cod Salad' is an exotic summer dish cent...   \n",
       "16  Which traditional Christian holiday, historica...   \n",
       "17  In the 'Popeye' comic strip and animated serie...   \n",
       "18  What colour coat does Rupert the Bear wear in ...   \n",
       "19  Pancetta is a type of what, commonly known as ...   \n",
       "20  A Paris grocer was jailed for two years in 197...   \n",
       "21  Whose 1995 best seller argues that our univers...   \n",
       "22  What key ingredient is 'Cape Cod Salad', an ex...   \n",
       "23  In Japan, what is the hibachi (heating applian...   \n",
       "24  Who is known for saying, \"Are you going to com...   \n",
       "25  To which royal house or dynasty did Malcolm II...   \n",
       "26  What is the numerical designation of the New Z...   \n",
       "27  The books 'Bridget Jones: The Edge of Reason' ...   \n",
       "28  Motor Racing. Which team announced its withdra...   \n",
       "\n",
       "                                         short_answer  \\\n",
       "0                                ['fancy dress shop']   \n",
       "1   ['handley page aircraft company' 'o 100 and o ...   \n",
       "2   ['estimating' 'estimated' 'estimate' 'overesti...   \n",
       "3   ['u s of america' 'u–s–' 'estatos unitos' 'ama...   \n",
       "4   ['㋃' 'april month' 'april' 'aprill' 'cruellest...   \n",
       "5                                        ['four' '4']   \n",
       "6   ['jacques benita' 'dior monsieur' 'christian d...   \n",
       "7              ['cock' 'cock disambiguation' 'cocks']   \n",
       "8   ['goti marbles in hindi' 'aggie marble' 'marbl...   \n",
       "9                                       ['1871 1909']   \n",
       "10  ['one thousand nine hundred and seventy three'...   \n",
       "11                   ['under' 'under disambiguation']   \n",
       "12  ['amos andy' 'brazilian brass mines' 'george 2...   \n",
       "13  ['felix mendelssohn' 'mendelsson bartholdy' 'f...   \n",
       "14  ['antelope case' '23 u s 66' 'antelope'\\n 'ant...   \n",
       "15                                        ['lobster']   \n",
       "16  ['whitsuntide' 'whitsun' 'whit sunday' 'whitsu...   \n",
       "17  ['popeye and olive oyl show' 'thimble theatre'...   \n",
       "18  ['red colour' 'incarnadined' 'reddened' 'aztec...   \n",
       "19  ['hickory bacon' 'side bacon' 'back rashers' '...   \n",
       "20                           ['wedge of hard cheese']   \n",
       "21  ['steven hawkins' 'stephen hawking' 'stephan h...   \n",
       "22                                        ['lobster']   \n",
       "23  ['cooking methods' 'cookery' 'par cooked' 'coo...   \n",
       "24  ['terence alan patrick seán milligan'\\n 'teren...   \n",
       "25  ['macmalcolm' 'canmore dynasty' 'canmores' 'du...   \n",
       "26  ['four' 'four tv channel nz' 'four new zealand...   \n",
       "27  ['bridget joneses diary' 'bridget jones diary'...   \n",
       "28  ['bmw z2' 'bavarian motor works' 'bayerische m...   \n",
       "\n",
       "                                model_original_answer  \\\n",
       "0                                  ['A costume shop']   \n",
       "1                                  ['Miles Aircraft']   \n",
       "2                                        ['Estimate']   \n",
       "3                                          ['Within']   \n",
       "4                                        ['February']   \n",
       "5                                               ['0']   \n",
       "6                            ['Cristóbal Balenciaga']   \n",
       "7   [\"Chi is not directly associated with a specif...   \n",
       "8                ['Nail polish finishes or textures']   \n",
       "9                                            ['1871']   \n",
       "10                                           ['1981']   \n",
       "11                                             ['Up']   \n",
       "12                                    ['I Love Lucy']   \n",
       "13                                 ['Richard Wagner']   \n",
       "14                                   ['Connochaetes']   \n",
       "15  ['Cape Cod Salad is an exotic summer dish cent...   \n",
       "16                                        ['May Day']   \n",
       "17                                         ['Popeye']   \n",
       "18                                         ['Yellow']   \n",
       "19                                     ['Cured meat']   \n",
       "20                ['For stabbing his wife to death.']   \n",
       "21                                    ['Paul Davies']   \n",
       "22  ['Cape Cod Salad is centered around fresh ingr...   \n",
       "23  ['A hibachi is used as a small heating device ...   \n",
       "24  ['This is a humorous or rhetorical question, o...   \n",
       "25                                 ['House of Alpin']   \n",
       "26         ['A Winchester bushel contains 64 pints.']   \n",
       "27                  ['[Error]: Max retries exceeded']   \n",
       "28                                          ['Honda']   \n",
       "\n",
       "                                 classifier_reasoning  original_f1  \\\n",
       "0   The query references 'Mr Benn,' a name that do...     0.400000   \n",
       "1   The query asks for the manufacturer of two air...     0.333333   \n",
       "2   The query hinges on two potentially ambiguous ...     1.000000   \n",
       "3   The query seeks clarification on the geographi...     0.000000   \n",
       "4   The query asks for the second month in the 'Ro...     0.000000   \n",
       "5   The BMW logo features three interlocked circle...     0.000000   \n",
       "6   The query contains three key components: the s...     0.000000   \n",
       "7   The query appears to ask for the Chinese zodia...     0.000000   \n",
       "8   The query asks for a categorization of multipl...     0.000000   \n",
       "9   The query requests 'a year in the life' of Joh...     0.666667   \n",
       "10  The query is underspecified due to several amb...     0.000000   \n",
       "11  The query seeks a single word that 'links' the...     0.000000   \n",
       "12  The query asks for a specific historical claim...     0.000000   \n",
       "13  The query asks about the author of a piece kno...     0.000000   \n",
       "14  The query asks about the species classificatio...     0.000000   \n",
       "15  The query mentions 'Cape Cod Salad' as an 'exo...     0.000000   \n",
       "16  The query asks for a holiday closely linked to...     0.000000   \n",
       "17  The query seeks to identify a fictional charac...     1.000000   \n",
       "18  The query references 'Rupert the Bear,' a well...     0.000000   \n",
       "19  The query asks for the broader category or cla...     0.000000   \n",
       "20  The query contains critical gaps and ambiguiti...     0.000000   \n",
       "21  The query specifies three critical pieces of i...     0.000000   \n",
       "22  The query appears to be incomplete, ending abr...     0.000000   \n",
       "23  The term 'hibachi' refers to at least two dist...     0.142857   \n",
       "24  The query contains metaphorical language and a...     0.000000   \n",
       "25  The query asks about Macbeth's royal affiliati...     0.666667   \n",
       "26  'Winchester' is not a standardized unit of mea...     0.000000   \n",
       "27  The query asks for a single novel that both 'T...     0.000000   \n",
       "28  The query seeks information about a specific t...     0.000000   \n",
       "\n",
       "    original_em  original_AA  \n",
       "0             0         0.75  \n",
       "1             0         0.00  \n",
       "2             1         0.50  \n",
       "3             0         0.25  \n",
       "4             0         0.00  \n",
       "5             0         0.00  \n",
       "6             0         0.00  \n",
       "7             0         0.00  \n",
       "8             0         0.00  \n",
       "9             0         0.50  \n",
       "10            0         0.00  \n",
       "11            0         0.00  \n",
       "12            0         0.00  \n",
       "13            0         0.00  \n",
       "14            0         0.50  \n",
       "15            0         0.00  \n",
       "16            0         0.00  \n",
       "17            1         0.50  \n",
       "18            0         0.00  \n",
       "19            0         0.25  \n",
       "20            0         0.00  \n",
       "21            0         0.00  \n",
       "22            0         0.00  \n",
       "23            0         0.75  \n",
       "24            0         0.00  \n",
       "25            0         0.00  \n",
       "26            0         0.00  \n",
       "27            0         0.00  \n",
       "28            0         0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_view = pd.DataFrame(question_modification)\n",
    "#df_view.to_csv(\"produced_files/modification_pilot.csv\")\n",
    "df_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060ea16",
   "metadata": {},
   "source": [
    "## Implementing QA on modified questions using GPT-4o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50df210",
   "metadata": {},
   "source": [
    "### Loading GPT-4o and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b162f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"https://api.openai.com/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca3a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_short_answer(question, client, model=\"gpt-4o-2024-11-20\", temperature=0, max_retries=5, sleep_time=2.0):\n",
    "    system_prompt = (\n",
    "        \"Answer the question with a concise response. \"\n",
    "        \"Return answers as a list of strings. If there's only one answer, return a single-item list. \"\n",
    "        \"Each answer should be brief and direct.\"\n",
    "    )\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": question}\n",
    "                ],\n",
    "                temperature=temperature\n",
    "            )\n",
    "            content = response.choices[0].message.content\n",
    "            if content.startswith(\"[\"):\n",
    "                return eval(content)\n",
    "            else:\n",
    "                return [content.strip()]\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            time.sleep(sleep_time * retries)\n",
    "            \n",
    "    return [\"[Error]: Max retries exceeded\"]\n",
    "\n",
    "def run_batch_shortQA_api(batch, client, **kwargs):\n",
    "    short_answers = []\n",
    "    for q in batch[\"modified_question\"]:\n",
    "        try:\n",
    "            answer = ask_short_answer(q, client=client, **kwargs)\n",
    "            short_answers.append(answer)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            short_answers.append([\"error\"])\n",
    "    return {\"model_new_answer\": short_answers}\n",
    "\n",
    "def batch_QA_with_progress(dataset, batch_fn, output_key, batch_size=10, fill_value=\"error\", **batch_fn_kwargs):\n",
    "    all_outputs = []\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=f\"Running {output_key}\"):\n",
    "        batch = dataset.select(range(i, min(i + batch_size, len(dataset))))\n",
    "        try:\n",
    "            output = batch_fn(batch, **batch_fn_kwargs)\n",
    "            if output_key not in output:\n",
    "                raise ValueError(f\"Missing key '{output_key}' in batch result\")\n",
    "            all_outputs.extend(output[output_key])\n",
    "        except Exception as e:\n",
    "            print(f\"Batch error at {i}: {e}\")\n",
    "            all_outputs.extend([fill_value] * len(batch))\n",
    "\n",
    "    if len(all_outputs) != len(dataset):\n",
    "        print(f\"[Warning] Output length mismatch, auto-filling\")\n",
    "        all_outputs.extend([fill_value] * (len(dataset) - len(all_outputs)))\n",
    "\n",
    "    return {output_key: all_outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798df69",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "651501df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff71be4241e74f26b660abfcf39c9d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modified_set = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_TriviaQA_UND_gpt_low_AA_samples_modified.jsonl\",\n",
    "    split=\"train\"  # 必须指定 split，否则默认返回 DatasetDict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6e4ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running model_new_answer: 100%|██████████| 3/3 [00:56<00:00, 18.98s/it]\n"
     ]
    }
   ],
   "source": [
    "modified_results = batch_QA_with_progress(\n",
    "    modified_set,\n",
    "    batch_fn=run_batch_shortQA_api,\n",
    "    output_key=\"model_new_answer\",\n",
    "    fill_value=[\"error\"],\n",
    "    client=client,\n",
    "    model=\"gpt-4o-2024-11-20\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0b82e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb221a51fe8b4618ae5f1b919be32266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_question</th>\n",
       "      <th>modified_question</th>\n",
       "      <th>short_answer</th>\n",
       "      <th>model_original_answer</th>\n",
       "      <th>classifier_reasoning</th>\n",
       "      <th>original_f1</th>\n",
       "      <th>original_em</th>\n",
       "      <th>original_AA</th>\n",
       "      <th>model_new_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When Mr Benn was looking for an adventure, wha...</td>\n",
       "      <td>In the children's animated series 'Mr Benn', w...</td>\n",
       "      <td>['fancy dress shop']</td>\n",
       "      <td>['A costume shop']</td>\n",
       "      <td>The query references 'Mr Benn,' a name that do...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[A costume shop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which company produced the Hastings and Herald...</td>\n",
       "      <td>Which British company produced the Handley Pag...</td>\n",
       "      <td>['handley page aircraft company' 'o 100 and o ...</td>\n",
       "      <td>['Miles Aircraft']</td>\n",
       "      <td>The query asks for the manufacturer of two air...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[- Handley Page Limited]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the Queen's horses won the 2013 Ascot...</td>\n",
       "      <td>Considering historical records do not substant...</td>\n",
       "      <td>['estimating' 'estimated' 'estimate' 'overesti...</td>\n",
       "      <td>['Estimate']</td>\n",
       "      <td>The query hinges on two potentially ambiguous ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[Speculative or fictional.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The expression 'Go West' originally (mid-1800s...</td>\n",
       "      <td>The expression 'Go West' originally (mid-1800s...</td>\n",
       "      <td>['u s of america' 'u–s–' 'estatos unitos' 'ama...</td>\n",
       "      <td>['Within']</td>\n",
       "      <td>The query seeks clarification on the geographi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[United States]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which month of the year came second in the Rom...</td>\n",
       "      <td>Which month was the second in the ancient Roma...</td>\n",
       "      <td>['㋃' 'april month' 'april' 'aprill' 'cruellest...</td>\n",
       "      <td>['February']</td>\n",
       "      <td>The query asks for the second month in the 'Ro...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[April]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How many ‘Triangles’ are there on the logo of ...</td>\n",
       "      <td>How many distinct colored sections, which are ...</td>\n",
       "      <td>['four' '4']</td>\n",
       "      <td>['0']</td>\n",
       "      <td>The BMW logo features three interlocked circle...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who created the ‘A’ Line in 1955?</td>\n",
       "      <td>Who created the 'A' Line fashion collection in...</td>\n",
       "      <td>['jacques benita' 'dior monsieur' 'christian d...</td>\n",
       "      <td>['Cristóbal Balenciaga']</td>\n",
       "      <td>The query contains three key components: the s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Christian Dior]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chi is the Chinese year of what?</td>\n",
       "      <td>What is the Chinese zodiac animal for the year...</td>\n",
       "      <td>['cock' 'cock disambiguation' 'cocks']</td>\n",
       "      <td>[\"Chi is not directly associated with a specif...</td>\n",
       "      <td>The query appears to ask for the Chinese zodia...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Rooster]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toothpaste, turtle, oxblood, oilie/oily, ade, ...</td>\n",
       "      <td>Toothpaste, turtle, oxblood, oilie/oily, ade, ...</td>\n",
       "      <td>['goti marbles in hindi' 'aggie marble' 'marbl...</td>\n",
       "      <td>['Nail polish finishes or textures']</td>\n",
       "      <td>The query asks for a categorization of multipl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Marbles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Give a year in the life of Irish playwright an...</td>\n",
       "      <td>What are the birth and death years of Irish pl...</td>\n",
       "      <td>['1871 1909']</td>\n",
       "      <td>['1871']</td>\n",
       "      <td>The query requests 'a year in the life' of Joh...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[1871, 1909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When was the current theme for the BBC televis...</td>\n",
       "      <td>When was the iconic theme tune 'Jessica' by Th...</td>\n",
       "      <td>['one thousand nine hundred and seventy three'...</td>\n",
       "      <td>['1981']</td>\n",
       "      <td>The query is underspecified due to several amb...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[1973]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What word links take, write and stand</td>\n",
       "      <td>Identify the single word that functions as a p...</td>\n",
       "      <td>['under' 'under disambiguation']</td>\n",
       "      <td>['Up']</td>\n",
       "      <td>The query seeks a single word that 'links' the...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[under]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What US sitcom was the first exported to Britain?</td>\n",
       "      <td>What US sitcom was the first to be broadcast b...</td>\n",
       "      <td>['amos andy' 'brazilian brass mines' 'george 2...</td>\n",
       "      <td>['I Love Lucy']</td>\n",
       "      <td>The query asks for a specific historical claim...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[I Love Lucy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Who wrote the piece of music recognised in mu...</td>\n",
       "      <td>Who composed the 'Wedding March' that is part ...</td>\n",
       "      <td>['felix mendelssohn' 'mendelsson bartholdy' 'f...</td>\n",
       "      <td>['Richard Wagner']</td>\n",
       "      <td>The query asks about the author of a piece kno...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Felix Mendelssohn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>To which species does the Gnu or Wildebeest be...</td>\n",
       "      <td>To what type of animal does the Gnu or Wildebe...</td>\n",
       "      <td>['antelope case' '23 u s 66' 'antelope'\\n 'ant...</td>\n",
       "      <td>['Connochaetes']</td>\n",
       "      <td>The query asks about the species classificatio...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[Mammal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'Cape Cod Salad' is an exotic summer dish centred</td>\n",
       "      <td>'Cape Cod Salad' is an exotic summer dish cent...</td>\n",
       "      <td>['lobster']</td>\n",
       "      <td>['Cape Cod Salad is an exotic summer dish cent...</td>\n",
       "      <td>The query mentions 'Cape Cod Salad' as an 'exo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Cranberries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What holiday is particularly associated with M...</td>\n",
       "      <td>Which traditional Christian holiday, historica...</td>\n",
       "      <td>['whitsuntide' 'whitsun' 'whit sunday' 'whitsu...</td>\n",
       "      <td>['May Day']</td>\n",
       "      <td>The query asks for a holiday closely linked to...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[May Day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Poopdeck Pappy is which fictional character’s ...</td>\n",
       "      <td>In the 'Popeye' comic strip and animated serie...</td>\n",
       "      <td>['popeye and olive oyl show' 'thimble theatre'...</td>\n",
       "      <td>['Popeye']</td>\n",
       "      <td>The query seeks to identify a fictional charac...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[Popeye]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What colour jumper does fictional character Ru...</td>\n",
       "      <td>What colour coat does Rupert the Bear wear in ...</td>\n",
       "      <td>['red colour' 'incarnadined' 'reddened' 'aztec...</td>\n",
       "      <td>['Yellow']</td>\n",
       "      <td>The query references 'Rupert the Bear,' a well...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Rupert the Bear is not a character from Beatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pancetta is a type of what?</td>\n",
       "      <td>Pancetta is a type of what, commonly known as ...</td>\n",
       "      <td>['hickory bacon' 'side bacon' 'back rashers' '...</td>\n",
       "      <td>['Cured meat']</td>\n",
       "      <td>The query asks for the broader category or cla...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[Cured pork belly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A Paris grocer was jailed for two years in 197...</td>\n",
       "      <td>A Paris grocer was jailed for two years in 197...</td>\n",
       "      <td>['wedge of hard cheese']</td>\n",
       "      <td>['For stabbing his wife to death.']</td>\n",
       "      <td>The query contains critical gaps and ambiguiti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[A baguette]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Whose 1995 best seller argues that our univers...</td>\n",
       "      <td>Whose 1995 best seller argues that our univers...</td>\n",
       "      <td>['steven hawkins' 'stephen hawking' 'stephan h...</td>\n",
       "      <td>['Paul Davies']</td>\n",
       "      <td>The query specifies three critical pieces of i...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Brian Greene]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'Cape Cod Salad' is an exotic summer dish centred</td>\n",
       "      <td>What key ingredient is 'Cape Cod Salad', an ex...</td>\n",
       "      <td>['lobster']</td>\n",
       "      <td>['Cape Cod Salad is centered around fresh ingr...</td>\n",
       "      <td>The query appears to be incomplete, ending abr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Cranberries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>In Japan, what is a hibachi used for?</td>\n",
       "      <td>In Japan, what is the hibachi (heating applian...</td>\n",
       "      <td>['cooking methods' 'cookery' 'par cooked' 'coo...</td>\n",
       "      <td>['A hibachi is used as a small heating device ...</td>\n",
       "      <td>The term 'hibachi' refers to at least two dist...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[The hibachi is used for heating and sometimes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Are you going to come quietly, or do I have to...</td>\n",
       "      <td>Who is known for saying, \"Are you going to com...</td>\n",
       "      <td>['terence alan patrick seán milligan'\\n 'teren...</td>\n",
       "      <td>['This is a humorous or rhetorical question, o...</td>\n",
       "      <td>The query contains metaphorical language and a...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Spike Milligan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Macbeth belonged to which royal house or dynasty?</td>\n",
       "      <td>To which royal house or dynasty did Malcolm II...</td>\n",
       "      <td>['macmalcolm' 'canmore dynasty' 'canmores' 'du...</td>\n",
       "      <td>['House of Alpin']</td>\n",
       "      <td>The query asks about Macbeth's royal affiliati...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[House of Dunkeld]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How many pints are there in a 'Winchester'?</td>\n",
       "      <td>What is the numerical designation of the New Z...</td>\n",
       "      <td>['four' 'four tv channel nz' 'four new zealand...</td>\n",
       "      <td>['A Winchester bushel contains 64 pints.']</td>\n",
       "      <td>'Winchester' is not a standardized unit of mea...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Channel 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The books 'The Edge of Reason' and 'Mad About ...</td>\n",
       "      <td>The books 'Bridget Jones: The Edge of Reason' ...</td>\n",
       "      <td>['bridget joneses diary' 'bridget jones diary'...</td>\n",
       "      <td>['[Error]: Max retries exceeded']</td>\n",
       "      <td>The query asks for a single novel that both 'T...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[[Error]: Max retries exceeded]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Motor Racing. Which team has announced that th...</td>\n",
       "      <td>Motor Racing. Which team announced its withdra...</td>\n",
       "      <td>['bmw z2' 'bavarian motor works' 'bayerische m...</td>\n",
       "      <td>['Honda']</td>\n",
       "      <td>The query seeks information about a specific t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Toyota]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_question  \\\n",
       "0   When Mr Benn was looking for an adventure, wha...   \n",
       "1   Which company produced the Hastings and Herald...   \n",
       "2   Which of the Queen's horses won the 2013 Ascot...   \n",
       "3   The expression 'Go West' originally (mid-1800s...   \n",
       "4   Which month of the year came second in the Rom...   \n",
       "5   How many ‘Triangles’ are there on the logo of ...   \n",
       "6                   Who created the ‘A’ Line in 1955?   \n",
       "7                    Chi is the Chinese year of what?   \n",
       "8   Toothpaste, turtle, oxblood, oilie/oily, ade, ...   \n",
       "9   Give a year in the life of Irish playwright an...   \n",
       "10  When was the current theme for the BBC televis...   \n",
       "11              What word links take, write and stand   \n",
       "12  What US sitcom was the first exported to Britain?   \n",
       "13  \"Who wrote the piece of music recognised in mu...   \n",
       "14  To which species does the Gnu or Wildebeest be...   \n",
       "15  'Cape Cod Salad' is an exotic summer dish centred   \n",
       "16  What holiday is particularly associated with M...   \n",
       "17  Poopdeck Pappy is which fictional character’s ...   \n",
       "18  What colour jumper does fictional character Ru...   \n",
       "19                        Pancetta is a type of what?   \n",
       "20  A Paris grocer was jailed for two years in 197...   \n",
       "21  Whose 1995 best seller argues that our univers...   \n",
       "22  'Cape Cod Salad' is an exotic summer dish centred   \n",
       "23              In Japan, what is a hibachi used for?   \n",
       "24  Are you going to come quietly, or do I have to...   \n",
       "25  Macbeth belonged to which royal house or dynasty?   \n",
       "26        How many pints are there in a 'Winchester'?   \n",
       "27  The books 'The Edge of Reason' and 'Mad About ...   \n",
       "28  Motor Racing. Which team has announced that th...   \n",
       "\n",
       "                                    modified_question  \\\n",
       "0   In the children's animated series 'Mr Benn', w...   \n",
       "1   Which British company produced the Handley Pag...   \n",
       "2   Considering historical records do not substant...   \n",
       "3   The expression 'Go West' originally (mid-1800s...   \n",
       "4   Which month was the second in the ancient Roma...   \n",
       "5   How many distinct colored sections, which are ...   \n",
       "6   Who created the 'A' Line fashion collection in...   \n",
       "7   What is the Chinese zodiac animal for the year...   \n",
       "8   Toothpaste, turtle, oxblood, oilie/oily, ade, ...   \n",
       "9   What are the birth and death years of Irish pl...   \n",
       "10  When was the iconic theme tune 'Jessica' by Th...   \n",
       "11  Identify the single word that functions as a p...   \n",
       "12  What US sitcom was the first to be broadcast b...   \n",
       "13  Who composed the 'Wedding March' that is part ...   \n",
       "14  To what type of animal does the Gnu or Wildebe...   \n",
       "15  'Cape Cod Salad' is an exotic summer dish cent...   \n",
       "16  Which traditional Christian holiday, historica...   \n",
       "17  In the 'Popeye' comic strip and animated serie...   \n",
       "18  What colour coat does Rupert the Bear wear in ...   \n",
       "19  Pancetta is a type of what, commonly known as ...   \n",
       "20  A Paris grocer was jailed for two years in 197...   \n",
       "21  Whose 1995 best seller argues that our univers...   \n",
       "22  What key ingredient is 'Cape Cod Salad', an ex...   \n",
       "23  In Japan, what is the hibachi (heating applian...   \n",
       "24  Who is known for saying, \"Are you going to com...   \n",
       "25  To which royal house or dynasty did Malcolm II...   \n",
       "26  What is the numerical designation of the New Z...   \n",
       "27  The books 'Bridget Jones: The Edge of Reason' ...   \n",
       "28  Motor Racing. Which team announced its withdra...   \n",
       "\n",
       "                                         short_answer  \\\n",
       "0                                ['fancy dress shop']   \n",
       "1   ['handley page aircraft company' 'o 100 and o ...   \n",
       "2   ['estimating' 'estimated' 'estimate' 'overesti...   \n",
       "3   ['u s of america' 'u–s–' 'estatos unitos' 'ama...   \n",
       "4   ['㋃' 'april month' 'april' 'aprill' 'cruellest...   \n",
       "5                                        ['four' '4']   \n",
       "6   ['jacques benita' 'dior monsieur' 'christian d...   \n",
       "7              ['cock' 'cock disambiguation' 'cocks']   \n",
       "8   ['goti marbles in hindi' 'aggie marble' 'marbl...   \n",
       "9                                       ['1871 1909']   \n",
       "10  ['one thousand nine hundred and seventy three'...   \n",
       "11                   ['under' 'under disambiguation']   \n",
       "12  ['amos andy' 'brazilian brass mines' 'george 2...   \n",
       "13  ['felix mendelssohn' 'mendelsson bartholdy' 'f...   \n",
       "14  ['antelope case' '23 u s 66' 'antelope'\\n 'ant...   \n",
       "15                                        ['lobster']   \n",
       "16  ['whitsuntide' 'whitsun' 'whit sunday' 'whitsu...   \n",
       "17  ['popeye and olive oyl show' 'thimble theatre'...   \n",
       "18  ['red colour' 'incarnadined' 'reddened' 'aztec...   \n",
       "19  ['hickory bacon' 'side bacon' 'back rashers' '...   \n",
       "20                           ['wedge of hard cheese']   \n",
       "21  ['steven hawkins' 'stephen hawking' 'stephan h...   \n",
       "22                                        ['lobster']   \n",
       "23  ['cooking methods' 'cookery' 'par cooked' 'coo...   \n",
       "24  ['terence alan patrick seán milligan'\\n 'teren...   \n",
       "25  ['macmalcolm' 'canmore dynasty' 'canmores' 'du...   \n",
       "26  ['four' 'four tv channel nz' 'four new zealand...   \n",
       "27  ['bridget joneses diary' 'bridget jones diary'...   \n",
       "28  ['bmw z2' 'bavarian motor works' 'bayerische m...   \n",
       "\n",
       "                                model_original_answer  \\\n",
       "0                                  ['A costume shop']   \n",
       "1                                  ['Miles Aircraft']   \n",
       "2                                        ['Estimate']   \n",
       "3                                          ['Within']   \n",
       "4                                        ['February']   \n",
       "5                                               ['0']   \n",
       "6                            ['Cristóbal Balenciaga']   \n",
       "7   [\"Chi is not directly associated with a specif...   \n",
       "8                ['Nail polish finishes or textures']   \n",
       "9                                            ['1871']   \n",
       "10                                           ['1981']   \n",
       "11                                             ['Up']   \n",
       "12                                    ['I Love Lucy']   \n",
       "13                                 ['Richard Wagner']   \n",
       "14                                   ['Connochaetes']   \n",
       "15  ['Cape Cod Salad is an exotic summer dish cent...   \n",
       "16                                        ['May Day']   \n",
       "17                                         ['Popeye']   \n",
       "18                                         ['Yellow']   \n",
       "19                                     ['Cured meat']   \n",
       "20                ['For stabbing his wife to death.']   \n",
       "21                                    ['Paul Davies']   \n",
       "22  ['Cape Cod Salad is centered around fresh ingr...   \n",
       "23  ['A hibachi is used as a small heating device ...   \n",
       "24  ['This is a humorous or rhetorical question, o...   \n",
       "25                                 ['House of Alpin']   \n",
       "26         ['A Winchester bushel contains 64 pints.']   \n",
       "27                  ['[Error]: Max retries exceeded']   \n",
       "28                                          ['Honda']   \n",
       "\n",
       "                                 classifier_reasoning  original_f1  \\\n",
       "0   The query references 'Mr Benn,' a name that do...     0.400000   \n",
       "1   The query asks for the manufacturer of two air...     0.333333   \n",
       "2   The query hinges on two potentially ambiguous ...     1.000000   \n",
       "3   The query seeks clarification on the geographi...     0.000000   \n",
       "4   The query asks for the second month in the 'Ro...     0.000000   \n",
       "5   The BMW logo features three interlocked circle...     0.000000   \n",
       "6   The query contains three key components: the s...     0.000000   \n",
       "7   The query appears to ask for the Chinese zodia...     0.000000   \n",
       "8   The query asks for a categorization of multipl...     0.000000   \n",
       "9   The query requests 'a year in the life' of Joh...     0.666667   \n",
       "10  The query is underspecified due to several amb...     0.000000   \n",
       "11  The query seeks a single word that 'links' the...     0.000000   \n",
       "12  The query asks for a specific historical claim...     0.000000   \n",
       "13  The query asks about the author of a piece kno...     0.000000   \n",
       "14  The query asks about the species classificatio...     0.000000   \n",
       "15  The query mentions 'Cape Cod Salad' as an 'exo...     0.000000   \n",
       "16  The query asks for a holiday closely linked to...     0.000000   \n",
       "17  The query seeks to identify a fictional charac...     1.000000   \n",
       "18  The query references 'Rupert the Bear,' a well...     0.000000   \n",
       "19  The query asks for the broader category or cla...     0.000000   \n",
       "20  The query contains critical gaps and ambiguiti...     0.000000   \n",
       "21  The query specifies three critical pieces of i...     0.000000   \n",
       "22  The query appears to be incomplete, ending abr...     0.000000   \n",
       "23  The term 'hibachi' refers to at least two dist...     0.142857   \n",
       "24  The query contains metaphorical language and a...     0.000000   \n",
       "25  The query asks about Macbeth's royal affiliati...     0.666667   \n",
       "26  'Winchester' is not a standardized unit of mea...     0.000000   \n",
       "27  The query asks for a single novel that both 'T...     0.000000   \n",
       "28  The query seeks information about a specific t...     0.000000   \n",
       "\n",
       "    original_em  original_AA  \\\n",
       "0             0         0.75   \n",
       "1             0         0.00   \n",
       "2             1         0.50   \n",
       "3             0         0.25   \n",
       "4             0         0.00   \n",
       "5             0         0.00   \n",
       "6             0         0.00   \n",
       "7             0         0.00   \n",
       "8             0         0.00   \n",
       "9             0         0.50   \n",
       "10            0         0.00   \n",
       "11            0         0.00   \n",
       "12            0         0.00   \n",
       "13            0         0.00   \n",
       "14            0         0.50   \n",
       "15            0         0.00   \n",
       "16            0         0.00   \n",
       "17            1         0.50   \n",
       "18            0         0.00   \n",
       "19            0         0.25   \n",
       "20            0         0.00   \n",
       "21            0         0.00   \n",
       "22            0         0.00   \n",
       "23            0         0.75   \n",
       "24            0         0.00   \n",
       "25            0         0.00   \n",
       "26            0         0.00   \n",
       "27            0         0.00   \n",
       "28            0         0.00   \n",
       "\n",
       "                                     model_new_answer  \n",
       "0                                    [A costume shop]  \n",
       "1                            [- Handley Page Limited]  \n",
       "2                         [Speculative or fictional.]  \n",
       "3                                     [United States]  \n",
       "4                                             [April]  \n",
       "5                                                 [4]  \n",
       "6                                    [Christian Dior]  \n",
       "7                                           [Rooster]  \n",
       "8                                           [Marbles]  \n",
       "9                                        [1871, 1909]  \n",
       "10                                             [1973]  \n",
       "11                                            [under]  \n",
       "12                                      [I Love Lucy]  \n",
       "13                                [Felix Mendelssohn]  \n",
       "14                                           [Mammal]  \n",
       "15                                      [Cranberries]  \n",
       "16                                          [May Day]  \n",
       "17                                           [Popeye]  \n",
       "18  [Rupert the Bear is not a character from Beatr...  \n",
       "19                                 [Cured pork belly]  \n",
       "20                                       [A baguette]  \n",
       "21                                     [Brian Greene]  \n",
       "22                                      [Cranberries]  \n",
       "23  [The hibachi is used for heating and sometimes...  \n",
       "24                                   [Spike Milligan]  \n",
       "25                                 [House of Dunkeld]  \n",
       "26                                        [Channel 1]  \n",
       "27                    [[Error]: Max retries exceeded]  \n",
       "28                                           [Toyota]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_modified = deepcopy(modified_set)\n",
    "for key in modified_results:\n",
    "    qa_modified = qa_modified.add_column(key, modified_results[key])\n",
    "\n",
    "qa_modified.to_json(\"BASELINE_TriviaQA_UND_gpt_low_AA_samples_modified.jsonl\", orient=\"records\", lines=True)\n",
    "df_qa_modified = pd.read_json(\"BASELINE_TriviaQA_UND_gpt_low_AA_samples_modified.jsonl\", lines=True)\n",
    "#df_qa_modified.to_csv('produced_files/modification_pilot_qa.csv')\n",
    "df_qa_modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904edcd",
   "metadata": {},
   "source": [
    "### Traditional Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac915dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_squad_per_sample_multi_ref_pred(dataset, pred_col=\"model_new_answer\", ref_col=\"short_answer\"):\n",
    "    \"\"\"\n",
    "    对每个样本逐一计算 EM 和 F1，支持多个参考答案和多个预测答案（list[str]）。\n",
    "    返回带 \"em\", \"f1\" 列的新 Dataset，以及 f1/em 列表用于统计分析。\n",
    "    Also considering multiple answers in both gold and pred and take the maximum score\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize_answer(s):\n",
    "        def remove_articles(text):\n",
    "            return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "        def white_space_fix(text):\n",
    "            return ' '.join(text.split())\n",
    "        def remove_punc(text):\n",
    "            return ''.join(ch for ch in text if ch not in string.punctuation)\n",
    "        def lower(text):\n",
    "            return text.lower()\n",
    "        return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "    def compute_exact(a_pred, a_gold):\n",
    "    # 如果是 list，转成 set 并 normalize 每个元素\n",
    "        if isinstance(a_pred, list) and isinstance(a_gold, list):\n",
    "          pred_set = set(normalize_answer(a) for a in a_pred)\n",
    "          gold_set = set(normalize_answer(a) for a in a_gold)\n",
    "          return int(pred_set == gold_set)\n",
    "        else:\n",
    "          return int(normalize_answer(a_pred) == normalize_answer(a_gold))\n",
    "\n",
    "    def compute_f1(a_pred, a_gold):\n",
    "        pred_tokens = normalize_answer(a_pred).split()\n",
    "        gold_tokens = normalize_answer(a_gold).split()\n",
    "        common = Counter(pred_tokens) & Counter(gold_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            return 0.0\n",
    "        precision = num_same / len(pred_tokens)\n",
    "        recall = num_same / len(gold_tokens)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    new_data = []\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "\n",
    "    for item in dataset:\n",
    "        preds = item.get(pred_col, [])\n",
    "        golds = item.get(ref_col, [])\n",
    "        # 转为 list\n",
    "        if not isinstance(preds, list):\n",
    "            preds = [preds] if preds else []\n",
    "        if not isinstance(golds, list):\n",
    "            golds = [golds] if golds else []\n",
    "\n",
    "        # 多对多最大匹配\n",
    "        if not preds or not golds:\n",
    "            em = 0.0\n",
    "            f1 = 0.0\n",
    "        else:\n",
    "            em = max(compute_exact(p, g) for p in preds for g in golds)\n",
    "            f1 = max(compute_f1(p, g) for p in preds for g in golds)\n",
    "\n",
    "        new_item = deepcopy(item)\n",
    "        new_item[\"new_em\"] = em\n",
    "        new_item[\"new_f1\"] = f1\n",
    "        new_data.append(new_item)\n",
    "        em_scores.append(em)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return Dataset.from_list(new_data), f1_scores, em_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a1574b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f313adf1d134d68a1433dbfdca6dfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad_scored_modified, modified_f1_list, modified_em_list = evaluate_squad_per_sample_multi_ref_pred(qa_modified)\n",
    "squad_scored_modified.to_json(\"BASELINE_TriviaQA_Gemini_modified_GPT_qa_squad_scores.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "df = pd.read_json(\"BASELINE_TriviaQA_Gemini_modified_GPT_qa_squad_scores.jsonl\", lines=True)\n",
    "df.to_csv('BASELINE_TriviaQA_Gemini_modified_GPT_qa_squad_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e218902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New answers after modification Exact Match (avg): 0.00\n",
      "New answers after modification F1 Score (avg): 15.18\n",
      "Original answers Exact Match (avg): 6.90\n",
      "Original answers F1 Score (avg): 14.52\n",
      "F1: t=0.096, p=0.9236\n",
      "EM: t=-1.440, p=0.1609\n"
     ]
    }
   ],
   "source": [
    "modified_mean_em = np.mean(modified_em_list)  # em_scores: EM list per sample\n",
    "modified_mean_f1 = np.mean(modified_f1_list)  # f1_scores F1 list per sample\n",
    "print(f\"New answers after modification Exact Match (avg): {modified_mean_em * 100:.2f}\")\n",
    "print(f\"New answers after modification F1 Score (avg): {modified_mean_f1 * 100:.2f}\")\n",
    "\n",
    "original_em_list = qa_modified['original_em']\n",
    "original_f1_list = qa_modified['original_f1']\n",
    "\n",
    "original_mean_em = np.mean(original_em_list)  # em_scores: EM list per sample\n",
    "original_mean_f1 = np.mean(original_f1_list)  # f1_scores F1 list per sample\n",
    "print(f\"Original answers Exact Match (avg): {original_mean_em * 100:.2f}\")\n",
    "print(f\"Original answers F1 Score (avg): {original_mean_f1 * 100:.2f}\")\n",
    "\n",
    "f1_tstat, f1_pval = ttest_ind(modified_f1_list, original_f1_list, equal_var=False)\n",
    "print(f\"F1: t={f1_tstat:.3f}, p={f1_pval:.4f}\")\n",
    "\n",
    "em_tstat, em_pval = ttest_ind(modified_em_list, original_em_list, equal_var=False)\n",
    "print(f\"EM: t={em_tstat:.3f}, p={em_pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fb9e3d",
   "metadata": {},
   "source": [
    "### Ragas AA evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a588426",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(ChatDeepSeek(model=\"deepseek-chat\", verbose=True, temperature=0))\n",
    "\n",
    "async def answer_accuracy_modified(input_dataset, evaluator=evaluator_llm):\n",
    "    # 在函数开始时创建一次 scorer\n",
    "    scorer = AnswerAccuracy(llm=evaluator)\n",
    "    \n",
    "\n",
    "    score_list = []\n",
    "        \n",
    "    for i, row in enumerate(tqdm(input_dataset, desc=\"Calculating short answer accuracy\")):\n",
    "        try:\n",
    "            # 短答案评分 - 处理列表情况\n",
    "            if 'short_answer' in row and 'model_new_answer' in row:\n",
    "                model_answers = row['model_new_answer'] if isinstance(row['model_new_answer'], list) else [row['model_new_answer']]\n",
    "                reference_answers = row['short_answer'] if isinstance(row['short_answer'], list) else [row['short_answer']]\n",
    "                    \n",
    "                # 计算所有组合的分数，取最高分\n",
    "                max_score = 0.0\n",
    "                for model_ans in model_answers:\n",
    "                    for ref_ans in reference_answers:\n",
    "                        sample = SingleTurnSample(\n",
    "                                user_input=row['modified_question'],\n",
    "                                response=model_ans,\n",
    "                                reference=ref_ans\n",
    "                            )\n",
    "                        score = await scorer.single_turn_ascore(sample)\n",
    "                        max_score = max(max_score, score)\n",
    "                        if max_score == 1.0:\n",
    "                            break  # 跳出内层循环\n",
    "                    if max_score == 1.0:\n",
    "                        break  # 跳出外层循环\n",
    "                \n",
    "                score_list.append(max_score)\n",
    "            else:\n",
    "                score_list.append(0.0)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"处理第 {i+1} 个样本时出错: {e}\")\n",
    "            score_list.append(0.0)\n",
    "\n",
    "    ragas_scored_dataset = input_dataset.add_column(\"new_AA\", score_list)\n",
    "\n",
    "    return ragas_scored_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82c358db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936151fda09a4d45b4532c4a4a9cd232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating short answer accuracy: 100%|██████████| 29/29 [04:12<00:00,  8.71s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672118d56b2d458aac8521cf081ab698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31670"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_scored_modified = load_dataset(\"json\",\n",
    "    data_files=\"BASELINE_TriviaQA_Gemini_modified_GPT_qa_squad_scores.jsonl\",\n",
    "    split=\"train\")\n",
    "result_with_AA = await answer_accuracy_modified(squad_scored_modified)\n",
    "result_with_AA.to_csv(\"BASELINE_TriviaQA_Gemini_modified_GPT_qa_all_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfedc5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original AA (avg): 13.79\n",
      "modified AA (avg): 54.31\n",
      "AA: t=4.061, p=0.0002\n"
     ]
    }
   ],
   "source": [
    "original_AA = list(result_with_AA[\"original_AA\"])\n",
    "modified_AA = list(result_with_AA[\"new_AA\"])\n",
    "\n",
    "original_mean_AA = np.mean(original_AA)\n",
    "print(f\"original AA (avg): {original_mean_AA * 100:.2f}\")\n",
    "\n",
    "\n",
    "modified_mean_AA = np.mean(modified_AA)\n",
    "print(f\"modified AA (avg): {modified_mean_AA * 100:.2f}\")\n",
    "\n",
    "AA_tstat, AA_pval = ttest_ind(modified_AA, original_AA, equal_var=False)\n",
    "print(f\"AA: t={AA_tstat:.3f}, p={AA_pval:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
